[
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_0",
    "text": "A R T I C L E\nA Robust Governance for the AI Act: AI Office,\nAI Board, Scientific Panel, and National Authorities\nClaudio Novelli1\n, Philipp Hacker2, Jessica Morley3, Jarle Trondal4,5,6 and Luciano Floridi3,1\n1Department of Legal Studies, University of Bologna, Bologna, IT, USA, 2European New School\nof Digital Studies, European University Viadrina, Frankfurt (Oder), Germany, 3Digital Ethics Center,\nYale University, New Haven, CT, USA, 4Department of Political Science and Management, University\nof Agder, Kristiansand, Norway, 5ARENA Centre for European Studies, University of Oslo, Oslo,\nNorway and 6Institute of European Studies, University of California, Berkeley, CA, USA\nCorresponding author: Claudio Novelli; Email: claudio.novelli@unibo.it\nAbstract\nRegulation is nothing without enforcement. This particularly holds for the dynamic field of emerging\ntechnologies. Hence, this article has two ambitions. First, it explains how the EU’s new Artificial\nIntelligence Act (AIA) may be implement",
    "source": "naive",
    "offset": 0
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_1",
    "text": "t. This particularly holds for the dynamic field of emerging\ntechnologies. Hence, this article has two ambitions. First, it explains how the EU’s new Artificial\nIntelligence Act (AIA) may be implemented and enforced by various institutional bodies, thus\nclarifying the governance framework of the AIA. Second, it proposes a normative governance model,\nproviding recommendations to ensure uniform and coordinated execution of the AIA and the\nfulfillment of the legislation. The article explores how the AIA may be implemented by national and\nEU institutional bodies, encompassing longstanding bodies, such as the European Commission, and\nthose newly established under the AIA, such as the AI Office. It investigates their roles across\nsupranational and national levels, emphasising how EU regulations influence institutional structures\nand operations. These regulations may not only directly dictate the structural design of institutions\nbut also indirectly request administrative capacities needed to",
    "source": "naive",
    "offset": 1
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_2",
    "text": "influence institutional structures\nand operations. These regulations may not only directly dictate the structural design of institutions\nbut also indirectly request administrative capacities needed to enforce the AIA.\nKeywords: AI Act; AI Office; EU governance\nI. Introduction\nThe effective implementation of the Artificial Intelligence Act (AIA) throughout the\nEuropean Union (EU) depends on a uniform, coordinated, and well-funded governance\nsetting.1 This is especially important given the increasing need for harmonised regulatory\napplication in the digital sector, as emphasised by EU policymakers due to the numerous\nlaws already enacted.2 For this purpose, the AIA, notably in Chapter VII (‘Governance’),\nunderscores the role of different institutional bodies, supranational and national, such as\nthe AI Office, the European AI Board, the Advisory Forum, the Scientific Panel, and\n(two) national competent authorities in each Member State. Close coordination between\nthese bodies is crucial fo",
    "source": "naive",
    "offset": 2
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_3",
    "text": " as\nthe AI Office, the European AI Board, the Advisory Forum, the Scientific Panel, and\n(two) national competent authorities in each Member State. Close coordination between\nthese bodies is crucial for implementing and enforcing the AIA’s rules across all Member\nCN’s contributions were supported by funding provided by Intesa Sanpaolo to the University of Bologna.\n© The Author(s), 2024. Published by Cambridge University Press. This is an Open Access article, distributed under the terms of the\nCreative Commons Attribution-ShareAlike licence (https://creativecommons.org/licenses/by-sa/4.0/), which permits re-use,\ndistribution, and reproduction in any medium, provided the same Creative Commons licence is used to distribute the re-used or\nadapted article and the original article is properly cited.\n1 This is explicitly stated by the AIA at Recital 148.\n2 J Tar, “Implementing Tech Rulebooks Should Be Top Digital Policy Priority, EU Countries Urge” <https://\nwww.euractiv.com/section/digital/ne",
    "source": "naive",
    "offset": 3
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_4",
    "text": "ed.\n1 This is explicitly stated by the AIA at Recital 148.\n2 J Tar, “Implementing Tech Rulebooks Should Be Top Digital Policy Priority, EU Countries Urge” <https://\nwww.euractiv.com/section/digital/news/implementing-tech-rulebooks-should-be-top-digital-policy-priority-eu-\ncountries-urge/> (accessed 25 March 2024).\nEuropean Journal of Risk Regulation (2024), 1–25\ndoi:10.1017/err.2024.57\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nStates. This interaction should also guarantee compatibility with other EU regulations to\navoid redundancy and antinomies.\nThis article explores how the AIA may be implemented by the EU institutional bodies,\nencompassing longstanding bodies, such as the European Commission (Commission), and\nthose newly established under the AIA, such as the AI Office. It investigates their roles\nacross supranational and national levels, emphasising how EU regulations influence\ninstitutional structures and operations. These regulations may ",
    "source": "naive",
    "offset": 4
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_5",
    "text": "A, such as the AI Office. It investigates their roles\nacross supranational and national levels, emphasising how EU regulations influence\ninstitutional structures and operations. These regulations may not only directly dictate the\nstructural design of institutions but also indirectly request administrative capacities needed\nto enforce the AIA.3\nThese deliberations share an important dynamic aspect: bodies enforcing the AIA will\noversee activities in various sectors due to the rapidly expanding reach of AI into all\nproducts and services. Interconnections with the enforcement of other recent EU\nlegislations and the digital industry, such as the Digital Services Act (DSA), are bound to\narise. Hence, at the EU and the national level, AIA enforcement bodies, such as the AI Office\nand specific national regulators, may ultimately be considered the nucleus of more\nencompassing “digital agencies,” bundling competencies and expertise across various\ndigital instruments. This raises the stakes of d",
    "source": "naive",
    "offset": 5
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_6",
    "text": "tional regulators, may ultimately be considered the nucleus of more\nencompassing “digital agencies,” bundling competencies and expertise across various\ndigital instruments. This raises the stakes of designing these entities wisely.\nDespite existing research on how EU regulatory governance influences national\ngovernance processes, we know little about how EU policy regulations shape states’\nenforcement infrastructures – that is, the organisational design of public administration.4\nTo explore this, we will delve into the institutional design of these bodies, which includes\nthe structure, competence, (division of) tasks, funding, and allocation of responsibilities.\nThe normative framework is becoming more established, especially after the\nconsolidation of the AIA, but there remains scope for additional adjustments in\nthe phase of implementing and delegated acts. The implementation stage enables the\nCommission and, on rare occasions, the Council of the European Union to fine-tune\nnon-essen",
    "source": "naive",
    "offset": 6
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_7",
    "text": "additional adjustments in\nthe phase of implementing and delegated acts. The implementation stage enables the\nCommission and, on rare occasions, the Council of the European Union to fine-tune\nnon-essential aspects of the legislation. Experts nominated by each Member State are\nconsulted before adopting these acts.\nAgainst this background, this article has two ambitions. First, it explains how the\nAIA may be implemented and enforced by supranational and national bodies, thus\nilluminating the governance framework of the AIA. Second, it proposes a normative\ngovernance model, providing recommendations to ensure uniform and coordinated\nexecution of the AIA and the fulfillment of the legislation. The awareness informs these\nrecommendations of the uncertainties surrounding the future development of AI\ntechnologies and their social impacts. This perspective leads us to endorse a model of\ngovernance characterised by its robustness. Robustness, in this sense, implies the ability to\nuphold core fun",
    "source": "naive",
    "offset": 7
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_8",
    "text": " AI\ntechnologies and their social impacts. This perspective leads us to endorse a model of\ngovernance characterised by its robustness. Robustness, in this sense, implies the ability to\nuphold core functions, purposes, and values and maintain critical structural or operational\narchitectures in the face of disruptive perturbations through adaptation and innovation.5\n3 Government structuring is a national prerogative, coined as national “administrative sovereignty” in extant\nliterature. The latter is understood as the legal right of final decision on the structuring of government and\nthe “assertion of control over recognisable administrative mechanisms of a government separate from the\ncomprehensive operation of a nation” in K Muth, “The Potential and Limits of Administrative Sovereignty”, The\nOxford Handbook of Global Policy and Transnational Administration (Oxford Academic 2019) 60 <https://academic.oup.\ncom/edited-volume/28088/chapter/212140358> (accessed 17 April 2024).\n4 A Benz, J Br",
    "source": "naive",
    "offset": 8
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_9",
    "text": "e\nOxford Handbook of Global Policy and Transnational Administration (Oxford Academic 2019) 60 <https://academic.oup.\ncom/edited-volume/28088/chapter/212140358> (accessed 17 April 2024).\n4 A Benz, J Broschek and M Lederer (eds), A Research Agenda for Multilevel Governance (Elgar 2021) <https://\nwww.e-elgar.com/shop/gbp/a-research-agenda-for-multilevel-governance-9781789908367.html> (accessed 17\nApril 2024); M Egeberg and J Trondal, “Researching European Union Agencies: What Have We Learnt (and\nWhere Do We Go from Here)?” (2017) 55 JCMS: Journal of Common Market Studies 675; Muth (n 4).\n5 C Ansell and others, “Robust Governance in Turbulent Times” (2024) Elements in Public Policy <https://www.\ncambridge.org/core/elements/robust-governance-in-turbulent-times/AB44DBE9AA636390EC114E8A428BF188> (accessed\n21 March 2024).\n2\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nThe article is structured as follows. Section II discusses general",
    "source": "naive",
    "offset": 9
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_10",
    "text": "(accessed\n21 March 2024).\n2\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nThe article is structured as follows. Section II discusses general considerations for the\ndesign of agencies and bodies tasked with AI legislative enforcement and supervision.\nSection III reviews the critical components for implementing the AIA, focusing on the\nCommission’s implementing and delegated acts. Section IV examines the supranational\nentities overseeing the AIA, including the AI Office, the AI Board, the Advisory Forum, and\nthe Scientific Panel, proposing measures to streamline the governance framework to\neliminate redundancies. Section V analyses national authorities’ roles – highlighting\nnotifying authorities, notified bodies, and market surveillance authorities. Section VI\noffers a set of recommendations derived from the analysis performed. The conclusion is\npresented in Section VII.\nII. General considerations: designing robust governance fo",
    "source": "naive",
    "offset": 10
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_11",
    "text": "ance authorities. Section VI\noffers a set of recommendations derived from the analysis performed. The conclusion is\npresented in Section VII.\nII. General considerations: designing robust governance for the AIA\nThis section discusses the potential goals, structures, interdependencies, and challenges of\nestablishing a multilevel governance framework for AI in the EU and Member States.\nII.1. EU level\nAt least three institutional design options are available at the EU level to establish\nexecutive capacities for regulating and enforcing AI.\nOption 1 suggests a centralised institutional design to incorporate tasks related to\nAI regulations within the remit of the Commission – notably within its departments, i.e., its\nDirectorates-General (DG). Such an approach could involve establishing a new DG (or a new\nunit within it) or reforming an existing one by increasing its policy portfolio to\nincorporate AI (e.g., Connect A responsible for Artificial Intelligence and Digital Industry).\nImplementin",
    "source": "naive",
    "offset": 11
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_12",
    "text": " (or a new\nunit within it) or reforming an existing one by increasing its policy portfolio to\nincorporate AI (e.g., Connect A responsible for Artificial Intelligence and Digital Industry).\nImplementing this structure would enhance the Commission’s ultimate control, oversight,\nand management of AI policy regulation and enforcement activities.\nOption 2 is a decentralised institutional design incorporating AI-related tasks in EU-level\nagencies. Similar to the Commission, this could involve either establishing a new AI agency\nat arm’s length from the Commission or a reformed EU agency incorporating AI tasks in its\ntask portfolio. Option 2 would thus leave the Commission with less control, oversight, and\nday-to-day management.\nOption 3 implements a hybrid institutional design with AI-related tasks established\nwithin the Commission in a designated DG, with one or several EU-level agencies\ngoverning at arm’s length from the Commission DG and working closely with other\nrelevant DGs. Existing l",
    "source": "naive",
    "offset": 12
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_13",
    "text": "sks established\nwithin the Commission in a designated DG, with one or several EU-level agencies\ngoverning at arm’s length from the Commission DG and working closely with other\nrelevant DGs. Existing literature suggests that most decentralised EU-level agencies keep\nstrong ties to what they consider their corresponding or “parent” DG.6 We consider\nthis the option most likely to result in suitably robust AI governance as it balances the\nstrengths and weaknesses of the other two options.\nII.2. Member state level\nEstablishing national agencies responsible\nfor enforcing AI regulations,\ntwo of\nwhich the AIA has already introduced, presents three institutional design options for\nconsideration.\nOption 1 would establish a new national agency dedicated to AI regulation enforcement.\nIts main benefit is creating a centralised body designed explicitly for AI oversight,\nattracting personnel with skills tailored to AI’s distinct requirements. However, it may lack\nindustry-specific expertise and risk ",
    "source": "naive",
    "offset": 13
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_14",
    "text": "is creating a centralised body designed explicitly for AI oversight,\nattracting personnel with skills tailored to AI’s distinct requirements. However, it may lack\nindustry-specific expertise and risk detachment from the intricacies of different sectors.\n6 Egeberg and Trondal (n 5).\nEuropean Journal of Risk Regulation\n3\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nMoreover, the urgency of the AIA’s application, with the first four editions effective from\nthe end of 2024, makes the typically lengthy process of legally and institutionally\nestablishing a new agency a significant drawback.\nOption 2 would simply assign the AIA’s enforcement to an existing agency. It capitalises\non the existing organisational framework and sectoral knowledge. For instance, the\nbanking sector has utilised machine learning models for decades,7 and banking authorities\nhave significant experience in testing and supervising these models, at least since the 2008\nfinancial crisi",
    "source": "naive",
    "offset": 14
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_15",
    "text": "e\nbanking sector has utilised machine learning models for decades,7 and banking authorities\nhave significant experience in testing and supervising these models, at least since the 2008\nfinancial crisis and the accompanying overhaul of the EU financial services and banking\nregulation.8 However, this could lead to disputes over mandate allocation and potentially\nnarrow the focus to specific sectors, ignoring the AI Act’s broad applicability.\nOption 3 would merge centralised expertise with sectoral insights by establishing a new\n“competence center”9 within an existing authority with AI experience, such as a banking\nor network regulator. The competence center would temporarily or permanently bring\ntogether AI experts from different backgrounds to form interdisciplinary teams (e.g., legal\nexperts and computer scientists) on specific cases. This approach aims to integrate\ncomprehensive AI knowledge with in-depth sectoral understanding despite potential\nrecruitment challenges, particularly fo",
    "source": "naive",
    "offset": 15
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_16",
    "text": "ts and computer scientists) on specific cases. This approach aims to integrate\ncomprehensive AI knowledge with in-depth sectoral understanding despite potential\nrecruitment challenges, particularly for technical positions.\nAs the implementation of the AIA at the State Member level is ongoing, the choice\namong the proposed options remains uncertain. Nonetheless, it is possible to speculate on\nthe effectiveness of these options. Using Germany as an illustrative example, Options 2 and\n3 are more robust than Option 1. Political dynamics and the convenience of existing\nframeworks may lead decision-makers to favor Option 2. Key agencies considered for AIA\noversight include the Federal Office for Information Security (BSI), the Federal Network\nAgency (BNetzA), and state data protection authorities, each with specific strengths and\nchallenges. BSI’s technical expertise is valuable for identifying AI risks, though it may not\ncover all regulatory aspects. BNetzA has a broad regulatory scope but ",
    "source": "naive",
    "offset": 16
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_17",
    "text": "s, each with specific strengths and\nchallenges. BSI’s technical expertise is valuable for identifying AI risks, though it may not\ncover all regulatory aspects. BNetzA has a broad regulatory scope but could lack AI-specific\nexpertise. State data protection authorities are well-versed in privacy issues but might not\nfully address AI’s broader impacts. However, Option 3 promises a more balanced mix of\nagility, specialised knowledge, and sector-wide understanding. Thus, an Option 3\ncompetence center, linked to the banking regulator (BaFin) or one of the other agencies\nmentioned (e.g., BNetzA), could offer the necessary flexibility and sectoral insight for\neffective AI regulation, leveraging BaFin’s experience in managing machine learning\nwithin financial oversight to meet the AI Act’s requirements, or BNetzA’s expertise in\ngoverning infrastructure and platforms (as the new national Digital Services Coordinator\nenforcing the Digital Services Act).\nThe effectiveness of these institutional de",
    "source": "naive",
    "offset": 17
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_18",
    "text": "ents, or BNetzA’s expertise in\ngoverning infrastructure and platforms (as the new national Digital Services Coordinator\nenforcing the Digital Services Act).\nThe effectiveness of these institutional designs may depend on the evolving framework\nat the EU level, which may ultimately determine what constitutes a robust institutional\ndesign at the national level.\nII.3. Multilevel: relationship between EU and national levels\nMultilevel\nadministrative\nsystems\nconsist\nof\nrelatively\nstable\narrangements\nof\nbureaucratic institutions and processes that span levels of government. Yet, depending\non the chosen institutional designs, different multilevel governing relationships are likely\nto unfold across levels of governance. Extant literature suggests multilevel governance\n7 E-I Dumitrescu and others, “Machine Learning or Econometrics for Credit Scoring: Let’s Get the Best of Both\nWorlds” (15 January 2021) <https://papers.ssrn.com/abstract=3553781> (accessed 26 March 2024).\n8 K Langenbucher, ‘Respon",
    "source": "naive",
    "offset": 18
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_19",
    "text": "Machine Learning or Econometrics for Credit Scoring: Let’s Get the Best of Both\nWorlds” (15 January 2021) <https://papers.ssrn.com/abstract=3553781> (accessed 26 March 2024).\n8 K Langenbucher, ‘Responsible A.I.-Based Credit Scoring – A Legal Framework’ (2020) 31 European Business\nLaw\nReview\n<https://kluwerlawonline.com/api/Product/CitationPDFURL?file=Journals\\EULR\\EULR2020022.\npdf> (accessed 26 March 2024).\n9 G Dimitropoulos and P Hacker, “Learning and the Law: Improving Behavioral Regulation from an\nInternational and Comparative Perspective” (2016) 25 Journal of Law and Policy 473.\n4\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nprocesses are particularly affected and biased by two institutional conditions. One is the\ndegree of administrative decentralisation – e.g., ‘agencification’10 – of national-level\ngovernment structures: the more task portfolios are hived off from ministries to agencies\nat the national level, the more ",
    "source": "naive",
    "offset": 19
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_20",
    "text": "dministrative decentralisation – e.g., ‘agencification’10 – of national-level\ngovernment structures: the more task portfolios are hived off from ministries to agencies\nat the national level, the more likely it is that these agencies, in turn, establish governing\nrelationships with ‘their’ sister agencies at EU-level. Hence, multilevel governing processes\nbetween agencies at both levels will likely emerge, leading to more uniform application\nand practice of EU regulations. Second, the more administrative capacities are established\nat the EU level, the stronger the pull effect of EU-level administrative institutions on\ncorresponding national-level institutions. One consequence is that government bureau-\ncrats may carry double-tasked roles in pursuing public governance. Double-tasked\ngovernment officials personalise multilevel administrative systems by working within\nnational ministries and agencies while partaking in EU administrative networks and\ninteracting with the EU-level executive ",
    "source": "naive",
    "offset": 20
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_21",
    "text": "nt officials personalise multilevel administrative systems by working within\nnational ministries and agencies while partaking in EU administrative networks and\ninteracting with the EU-level executive branch of government.11\nIII. The AIA implementation and enforcement: the tasks of the Commission\nImplementing the AIA and its enforcement involves several non-legislative acts primarily\nunder the Commission’s authority according to the EU’s rules for implementing powers,\nthe so-called committee procedure12 (Recital 86 AIA).13 A notable initial step in this process\nwas the establishment of the AI Office, formalised by the Commission’s Decision on\n24 January 2024. The remaining steps that must be taken by the Commission to implement\nand enforce the AIA are summarised in Table 1 and described in more detail subsequently.\nIII.1. Procedures\nThe European Commission is required to engage with Member State experts and\nrepresentatives when adopting implementing and delegated acts to ensure the cons",
    "source": "naive",
    "offset": 21
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_22",
    "text": "more detail subsequently.\nIII.1. Procedures\nThe European Commission is required to engage with Member State experts and\nrepresentatives when adopting implementing and delegated acts to ensure the consistent\napplication and detailed implementation of EU laws. Implementing acts aim to apply EU\nlaws consistently across Member States without altering the law (Article 291 TFEU). In\ncontrast, delegated acts are designed to supplement or modify non-essential elements of\nlegislative acts, adding details needed for their implementation (Article 290 TFEU).\nImplementing acts, governed by the comitology procedure, involve collaboration with a\ncommittee of Member State representatives. Under the AIA, this engagement involves\nonly the European AI Board. Delegated acts require consultation with Member State\nexperts but do not involve a formal committee.14 Delegated acts are subject to scrutiny by\nthe European Parliament and the Council, which have two months to raise objections;\notherwise, the Act is",
    "source": "naive",
    "offset": 22
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_23",
    "text": "ate\nexperts but do not involve a formal committee.14 Delegated acts are subject to scrutiny by\nthe European Parliament and the Council, which have two months to raise objections;\notherwise, the Act is adopted. The Commission’s powers under the AIA, including adopting\ndelegated acts, are granted for five years and can be silently renewed unless opposed by\nthe European Parliament (EP) and Council (Article 73 AIA). The Commission must keep\nthe EP and Council informed about delegated acts and report on its activities within nine\nmonths, allowing for oversight and potential revocation of its powers. Additionally, the\n10 An agency is an administrative body that is formally separated from a ministerial, or cabinet-level,\ndepartment and that carries out public tasks at a national level permanently, is staffed by public servants, is\nfinanced mainly by the state budget, and is subject to public legal procedures. Agencies are supposed to enjoy\nsome autonomy from their respective ministerial depar",
    "source": "naive",
    "offset": 23
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_24",
    "text": ", is staffed by public servants, is\nfinanced mainly by the state budget, and is subject to public legal procedures. Agencies are supposed to enjoy\nsome autonomy from their respective ministerial departments about decision-making. Over time, agencies tend\nto be moved out of and into ministerial departments, often cyclically (Bach and Jann 2010; Verhoest et al. 2012).\n11 J Trondal, An Emergent European Executive Order (Oxford University Press 2010).\n12 Regulation (EU) No 182/2011 dated 16 February 2011.\n13 GJ Brandsma and J Blom-Hansen, Controlling the EU Executive? The Politics of Delegation in the European Union\n(Oxford University Press 2017).\n14 P Craig, Delegated and Implementing Acts (1st edn, Oxford University Press 2018) <https://ora.ox.ac.uk/obje\ncts/uuid:f8aa03ad-60c1-4415-b5b5-0863b005407d> (accessed 26 February 2024).\nEuropean Journal of Risk Regulation\n5\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nCommission is tasked with publishing gui",
    "source": "naive",
    "offset": 24
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_25",
    "text": "b005407d> (accessed 26 February 2024).\nEuropean Journal of Risk Regulation\n5\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nCommission is tasked with publishing guidelines and making binding decisions to\nimplement the AIA effectively. The AI Office will support the adoption of implementing\nand delegated acts, while the AI Board focuses on implementing acts (see Section III).\nIII.2. Guidelines operationalising the risk-based approach\nThe Commission develops guidelines and updates them to assist in implementing the AIA’s\nrisk-based approach, focusing on classifying high-risk AI systems (Article 6(5) AIA).\nAdditionally, the Commission uses delegated acts to update Annex III, either adding new\nhigh-risk AI use cases or removing ones that no longer pose significant risks, based on\ncriteria such as likelihood of use, autonomy, human oversight, and outcome reversibility,\nensuring that these adjustments do not compromise the EU’s health, safety, and rights\ns",
    "source": "naive",
    "offset": 25
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_26",
    "text": "ficant risks, based on\ncriteria such as likelihood of use, autonomy, human oversight, and outcome reversibility,\nensuring that these adjustments do not compromise the EU’s health, safety, and rights\nstandards (Article 7 AIA).\nTable 1. Tasks and responsibilities of the Commission in implementing and enforcing the AIA\nKey aspects\nTasks and responsibilities of the Commission\na) Procedures\n- Establish and work with the AI Office and AI Board to develop\nimplementing and delegated acts\n- Conduct the comitology procedure with Member States for adopting and\nimplementing acts\n- Manage delegated act adoption, consulting experts, and undergoing\nscrutiny by EP and Council\nb) Guidelines\n- Issue guidelines on applying the definition of an AI system and\nclassification rules for high-risk systems\n- Create risk assessment methods for identifying and mitigating risks\n- Define rules for “significant modifications” that alter the risk level of a\nhigh-risk system\nc) Classification\n- Update Annex III to add",
    "source": "naive",
    "offset": 26
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_27",
    "text": " risk assessment methods for identifying and mitigating risks\n- Define rules for “significant modifications” that alter the risk level of a\nhigh-risk system\nc) Classification\n- Update Annex III to add or remove high-risk AI system use cases\nthrough delegated acts\n- Classify GPAI as exhibiting “systemic risk” based on criteria like FLOPs and\nhigh-impact capabilities\n- Adjust regulatory parameters (thresholds, benchmarks) for GPAI\nclassification through delegated acts\nd) Prohibited Systems\n- Develop guidelines on AI practices that are prohibited under Article 5\n(AIA)\n- Set standards and best practices to counter manipulative techniques and\nhazards\n- Define criteria for exceptions to prohibitions, e.g., for law enforcement\nuse of real-time remote biometric identification\ne) Harmonised standards and\nhigh-risk obligations\n- Define harmonised standards and obligations for high-risk system\nproviders, including in-door risk management system (Article 9 AIA)\n- Standardise technical documentatio",
    "source": "naive",
    "offset": 27
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_28",
    "text": "ds and\nhigh-risk obligations\n- Define harmonised standards and obligations for high-risk system\nproviders, including in-door risk management system (Article 9 AIA)\n- Standardise technical documentation requirements and - update Annex IV\nvia delegated acts as necessary\n- Approve codes of practice (Article 56(6) AIA)\nf) Information and Transparency\n- Set information obligations for providers of high-risk systems\nthroughout the AI value chain\n- Issue guidance to ensure compliance with transparency requirements,\nespecially for GPAI\ng) Enforcement\n- Clarify the interplay between the AIA and other EU legislative\nframeworks\n- Regulate regulatory sandboxes and supervisory functions\n- Oversee Member State setting of penalties and enforcement measures\nthat are effective, proportionate, and deterrent\n6\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nConsidering the risk-based classification of AI systems, which potentially offers a robust\n",
    "source": "naive",
    "offset": 28
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_29",
    "text": "\n6\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nConsidering the risk-based classification of AI systems, which potentially offers a robust\nregulatory approach by building in regulatory flexibility and applies to general-purpose AI\n(GPAI, also known as foundation models) albeit under a distinct terminology – namely, the\n‘high impact capabilities’ (Article 51(1) AIA) – these guidelines should also detail\nmethodologies for risk assessments.15\nSignificantly, within this framework, the Commission must define the rules about\n“significant modifications” that alter the risk level of a (high-risk) system once it has been\nintroduced to the market or put into use (Articles 25(1) and 3(23)). These alterations, not\nanticipated or accounted for in the initial conformity assessment conducted by the provider,\nmay require the system to be reclassified (Article 96(1), AIA). This involves specifying what\namounts to a significant change and outl",
    "source": "naive",
    "offset": 29
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_30",
    "text": "r in the initial conformity assessment conducted by the provider,\nmay require the system to be reclassified (Article 96(1), AIA). This involves specifying what\namounts to a significant change and outlining the procedures for performing a new\nconformity assessment (Article 43(4) AIA). Importantly, delineating a significant modifica-\ntion must refer to the purpose of these sections of the AIA, specifically, hedging some specific\nrisks of AI systems in the light of fundamental rights. Hence, only a noticeable, clear, and\nrelevant change to the system’s risks – such as discrimination, opacity, unforeseeability,\nprivacy, or the environment – can be a significant modification, in our view. It follows that a\nstandard fine-tuning exercise of foundation models should not lead to a substantial\nmodification unless the process involves, explicitly, particularly biased data sets, the\nremoval of safety layers, or other actions clearly entailing novel or increased risks.16\nA complementary yet potenti",
    "source": "naive",
    "offset": 30
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_31",
    "text": "ication unless the process involves, explicitly, particularly biased data sets, the\nremoval of safety layers, or other actions clearly entailing novel or increased risks.16\nA complementary yet potentially synergistic approach is to adopt pre-determined\nchange management plans akin to those in medicine.17 These plans are comprehensive\ndocuments outlining anticipated modifications to an AI system – covering aspects like\nmodel performance adjustments, data inputs, and shifts in intended use – and the methods\nfor assessing such changes. They might establish a proactive accountability methodology18\nfor identifying risks and devising mitigation strategies, ensuring modifications align with\nfundamental rights and AIA goals. Regulators would evaluate these plans during the AI\ntechnology’s premarket assessment, allowing post-market changes to be efficiently\nimplemented according to the pre-approved plan. Such change management plans do not\namount to a substantial modification in the sense of th",
    "source": "naive",
    "offset": 31
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_32",
    "text": "t assessment, allowing post-market changes to be efficiently\nimplemented according to the pre-approved plan. Such change management plans do not\namount to a substantial modification in the sense of the AIA as they are not unforeseen or\nunplanned (Article 3(23), AIA). Hence, they afford the distinct advantage of obviating the\nneed for reclassification and a new conformity assessment. However, they cannot capture\ndynamic and spontaneous changes by developers or deployers.\nIII.3. Classification of GPAI\nThe Commission has notable authority under the AIA to classify GPAI as exhibiting\n‘systemic risk’ (Article 51 AIA).19 This distinction, establishing the famous two-tiered\napproach to the regulation of GPAI,20 is crucial: only systemically risky GPAIs are subject to\nthe more far-reaching AI safety obligations concerning evaluation and red teaming,\n15 C Novelli and others, “AI Risk Assessment: A Scenario-Based, Proportional Methodology for the AI Act” (2024)\n3 Digital Society 13; C Novelli an",
    "source": "naive",
    "offset": 32
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_33",
    "text": "ty obligations concerning evaluation and red teaming,\n15 C Novelli and others, “AI Risk Assessment: A Scenario-Based, Proportional Methodology for the AI Act” (2024)\n3 Digital Society 13; C Novelli and others, “Taking AI Risks Seriously: A New Assessment Model for the AI Act”\n(2023) AI & SOCIETY <https://doi.org/10.1007/s00146-023-01723-z> (accessed 21 July 2023).\n16 C Novelli and others, “Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity”\n(14 January 2024) <https://papers.ssrn.com/abstract=4694565> (accessed 28 March 2024).\n17 KN Vokinger and U Gasser, “Regulating AI in Medicine in the United States and Europe” (2021) 3 Nature\nMachine Intelligence 738; J Morley and others, “Governing Data and Artificial Intelligence for Health Care:\nDeveloping an International Understanding” (2022) 6 JMIR Formative Research e31623.\n18 C Novelli, M Taddeo and L Floridi, “Accountability in Artificial Intelligence: What It Is and How It Works”\n(2023) AI & SOCIETY <http",
    "source": "naive",
    "offset": 33
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_34",
    "text": "ational Understanding” (2022) 6 JMIR Formative Research e31623.\n18 C Novelli, M Taddeo and L Floridi, “Accountability in Artificial Intelligence: What It Is and How It Works”\n(2023) AI & SOCIETY <https://doi.org/10.1007/s00146-023-01635-y> (accessed 31 July 2023).\n19 What counts as a systemic risk in this field is stated at art. 51, point 1 AIA.\n20 P Hacker, A Engel and M Mauer, “Regulating ChatGPT and Other Large Generative AI Models” (arXiv,\n10 February 2023) <http://arxiv.org/abs/2302.02337> (accessed 14 February 2023).\nEuropean Journal of Risk Regulation\n7\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\ncomprehensive risk assessment and mitigation, incident reporting, and cybersecurity\n(Article 55 AIA). The classification authority is delineated in Article 51 AIA, which outlines\nthe criteria according to which a GPAI is considered to exhibit systemic risk. The decision\nto classify a GPAI as systemically risky can be initiated by the Commission its",
    "source": "naive",
    "offset": 34
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_35",
    "text": "ticle 51 AIA, which outlines\nthe criteria according to which a GPAI is considered to exhibit systemic risk. The decision\nto classify a GPAI as systemically risky can be initiated by the Commission itself or in\nresponse to a qualified alert from the Scientific Panel confirming the presence of such\nhigh-impact capabilities.\nThe Commission may dynamically adjust regulatory parameters – such as thresholds,\nbenchmarks, and indicators – through delegated acts. The adaptive mechanism is essential\nfor a robust governance model as it ensures that regulations remain relevant amidst the\nfast pace of technological advancements, including algorithm improvements and\nhardware efficiency. The capacity to refine these regulatory measures is particularly\nvital as the trend in AI development moves towards creating more powerful yet “smaller”\nmodels that require fewer floating-point operations (FLOPs).21\nAgainst this background, Article 52 outlines a process allowing GPAI providers to\ncontest the Commissi",
    "source": "naive",
    "offset": 35
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_36",
    "text": "eating more powerful yet “smaller”\nmodels that require fewer floating-point operations (FLOPs).21\nAgainst this background, Article 52 outlines a process allowing GPAI providers to\ncontest the Commission’s classification decisions. This provision is pivotal, potentially\nbecoming a primary area of contention within the AI Act, akin to the legal disputes\nobserved under the DSA, where entities like Zalando and Amazon have disputed their\ncategorisation as Very Large Online Platforms.22 Particularly, GPAI providers whose\nmodels are trained with fewer than 10^25 FLOPs yet are deemed systemically risky are\nexpected to use this mechanism actively, possibly leading to legal challenges that could\nreach the Court of Justice of the European Union (CJEU). The legal recourse presented here\nis a double-edged sword. On the one hand, it constitutes an essential component of the AIA,\noffering a counterbalance to the Commission’s regulatory powers and ensuring a venue for\naddressing potential methodologic",
    "source": "naive",
    "offset": 36
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_37",
    "text": "ged sword. On the one hand, it constitutes an essential component of the AIA,\noffering a counterbalance to the Commission’s regulatory powers and ensuring a venue for\naddressing potential methodological errors or disputes over classifications. On the other\nhand, it provides a venue for providers with deep pockets to delay the application of the\nmore stringent rules for systemically relevant GPAI. Simultaneously, this reinforces the\nimportance of the presumptive 10^25 FLOP threshold – which is outdating rapidly due to\nthe growing capabilities of smaller foundation models.\nIII.4. Prohibited systems\nThe Commission is tasked with developing guidelines to address prohibited AI practices\n(Article 5, AIA), including setting technical standards and best practices for AI system design\nto prevent manipulative techniques. It must also define criteria for exceptions where AI can\nbe used to address significant threats or terrorist activities, with specific allowances for law\nenforcement, such as th",
    "source": "naive",
    "offset": 37
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_38",
    "text": "nipulative techniques. It must also define criteria for exceptions where AI can\nbe used to address significant threats or terrorist activities, with specific allowances for law\nenforcement, such as the use of real-time remote biometric identification in public spaces.\nThese guidelines will also outline necessary procedural safeguards to ensure such exceptions\ndo not infringe on fundamental rights. They will be crucial to balance law enforcement needs\nwith individual privacy and freedom protections.23\nIII.5. Harmonised standards and high-risk obligations\nThe Commission must also set harmonised standards and define obligations for providers\nof high-risk AI systems under the AIA, requiring a comprehensive “in-door” risk\nmanagement process that is continuous and iterative throughout the system’s lifecycle.\n21 S Ma and others, “The Era of 1-Bit LLMs: All Large Language Models Are in 1.58 Bits” (arXiv, 27 February 2024)\n<http://arxiv.org/abs/2402.17764> (accessed 28 March 2024).\n22 FY Chee a",
    "source": "naive",
    "offset": 38
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_39",
    "text": "’s lifecycle.\n21 S Ma and others, “The Era of 1-Bit LLMs: All Large Language Models Are in 1.58 Bits” (arXiv, 27 February 2024)\n<http://arxiv.org/abs/2402.17764> (accessed 28 March 2024).\n22 FY Chee and FY Chee, “Amazon Makes First Big Tech Challenge to EU Online Content Rules” Reuters (11 July\n2023)\n<https://www.reuters.com/technology/amazon-challenges-eu-online-content-rules-says-unfairly-single\nd-out-2023-07-11/> (accessed 28 March 2024).\n23 Notably, a recent CJEU Decision (Case-588/21) mandates the public disclosure of harmonised technical\nstandards to reinforce principles of the rule of law and free access to the law.\n8\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nThis includes detailing timelines, design choices, data processing methods, and strategies\nto mitigate biases, alongside standardising technical documentation as per Annex IV, with\nupdates via delegated acts to adapt to technological advances and ensure complia",
    "source": "naive",
    "offset": 39
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_40",
    "text": "ssing methods, and strategies\nto mitigate biases, alongside standardising technical documentation as per Annex IV, with\nupdates via delegated acts to adapt to technological advances and ensure compliance with\nregulatory standards.\nIII.6. Information and transparency\nThe Commission is also responsible for setting forth information obligations along the AI\nvalue chain that reflect the current technological standards for providers of high-risk\nsystems (Article 28 AIA) and offering guidance to ensure compliance with transparency\nrequirements, which holds particular significance for GPAI (Article 53 AIA). To achieve\nthis, the Commission might, for example, issue directives on properly revealing the use of\nGPAI across different settings, considering the medium and essence of the content\nimplicated.\nIII.7. Overlap with other regulations and enforcement timeline\nFinally, the Commission must elucidate the interplay between the AIA and other EU\nlegislative frameworks to guarantee internal system",
    "source": "naive",
    "offset": 40
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_41",
    "text": "ed.\nIII.7. Overlap with other regulations and enforcement timeline\nFinally, the Commission must elucidate the interplay between the AIA and other EU\nlegislative frameworks to guarantee internal systematicity and consistent enforcement\nacross the board. Specifically, the Commission may need to offer illustrative examples of\npotential overlaps or conflicts and promoting the formation of joint oversight entities or\nworking groups. Such initiatives would facilitate the exchange of information, standardise\nenforcement approaches, and develop unified interpretative guidelines, ensuring a\nharmonised regulatory landscape across the European Union.\nThe AIA’s enforcement is structured in stages, with transition periods for compliance\nvarying by the risk level of AI systems and linked to the Act’s official entry into force.\nSpecific grace periods are set for different categories of AI systems, ranging from 6 to 36\nmonths. However, for existing GPAI systems already on the market, a grace period of",
    "source": "naive",
    "offset": 41
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_42",
    "text": "ficial entry into force.\nSpecific grace periods are set for different categories of AI systems, ranging from 6 to 36\nmonths. However, for existing GPAI systems already on the market, a grace period of 24\nmonths is granted before they must comply fully (Article 83(3) AIA). Even more\nimportantly, high-risk systems already on the market 24 months after the entry into force\nare entirely exempt from the AIA until significant changes are made in their designs\n(Article 83(2) AIA). Conceptually, this meaningful change can be equated with the\nsubstantial modification discussed above. Arguably, however, this blank exemption is in\ndeep tension with a principle of product safety law: it applies to all models on the market,\nirrespective of when they entered the market. Moreover, the grace period for GPAI and the\nexemption for existing high-risk systems favor incumbents vis-à-vis newcomers, which is\nquestionable from a competition perspective.\nIV. Supranational authorities: the AI Office, the AI Boa",
    "source": "naive",
    "offset": 42
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_43",
    "text": "AI and the\nexemption for existing high-risk systems favor incumbents vis-à-vis newcomers, which is\nquestionable from a competition perspective.\nIV. Supranational authorities: the AI Office, the AI Board, and the\nother bodies\nThe AIA mandates a comprehensive governance framework, as highlighted in Recital 5 of\nthe Commission’s Decision that establishes the AI Office. Under this framework, the AI\nOffice is responsible for overseeing AI advancements, liaising with the scientific\ncommunity, and playing a pivotal role in investigations, testing, and enforcement, all\nwhile maintaining a global perspective.\nThe governance structure proposed by the AIA involves establishing national and\nsupranational bodies. Two key institutions are formed at the supranational level: the AI\nOffice and the European AI Board. While distinct in structure and task, these entities are\nsomehow complementary. The AI Office is anticipated to focus on regulatory oversight and\nenforcement, especially concerning GPAI mod",
    "source": "naive",
    "offset": 43
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_44",
    "text": " AI Board. While distinct in structure and task, these entities are\nsomehow complementary. The AI Office is anticipated to focus on regulatory oversight and\nenforcement, especially concerning GPAI models. The European AI Board is expected to\nEuropean Journal of Risk Regulation\n9\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nensure coordination among Member States, enhancing the AIA’s implementation through\nadvice, consultation, and awareness initiatives. Besides these two, the AIA also introduces\nother significant, though partially autonomous, supranational bodies, namely the\nScientific Panel and the Advisory Forum.\nTable 2 below outlines the structure, composition, missions, and tasks of the\ninstitutional bodies implementing and enforcing the AIA. It provides a foundation for the\nmore detailed discussion to follow in subsequent sections.\nIV.1. The AI Office\nThe first step in implementing the AIA was establishing a centralised AI Office, in January\n",
    "source": "naive",
    "offset": 44
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_45",
    "text": "rovides a foundation for the\nmore detailed discussion to follow in subsequent sections.\nIV.1. The AI Office\nThe first step in implementing the AIA was establishing a centralised AI Office, in January\n2024.24 Its primary mission is to lay down harmonised rules to implement and enforce the\nAIA consistently across the EU. The formation of the AI Office is geared towards unifying\nEurope’s AI expertise by leveraging insights from the scientific domain. In implementing\nthe AI Act, much will depend on “getting the AI Office right.”\nThe Office’s broad mandate involves collaboration with scientific experts, national\nauthorities, industry representatives, and significant institutions like the European High-\nPerformance Computing Joint Undertaking and international organisations. An important\naspect of the AI Office’s role is overseeing General-Purpose AI (GPAI) technologies,\nexemplified by ChatGPT and Gemini (e.g., Articles 52 to 56 AIA).\na. Institutional identity, composition, and operational a",
    "source": "naive",
    "offset": 45
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_46",
    "text": "of the AI Office’s role is overseeing General-Purpose AI (GPAI) technologies,\nexemplified by ChatGPT and Gemini (e.g., Articles 52 to 56 AIA).\na. Institutional identity, composition, and operational autonomy\nRegarding its institutional identity, the AI Office resembles EU interinstitutional services,\nmarked by its focused scope – currently dedicated solely to implementing the AIA – and its\nrole in providing cross-support to various institutions such as the EP, Council, and the\nCentral Bank. Like interinstitutional services, it extends support to agencies and bodies like\nthe European Data Protection Board and the European Investment Bank. It is explicitly\nstipulated in Articles 5 and 6 of the Commission’s Decision that the AI Office is entrusted\nwith supporting the European Artificial Intelligence Board and collaborating with the\nCentre for Algorithmic Transparency. This places the AI Office alongside other\ninterinstitutional services, such as the Computer Emergency Response Team (CERT-",
    "source": "naive",
    "offset": 46
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_47",
    "text": "ligence Board and collaborating with the\nCentre for Algorithmic Transparency. This places the AI Office alongside other\ninterinstitutional services, such as the Computer Emergency Response Team (CERT-EU),\nillustrating its distinctive function within the EU framework.\nHowever, unlike interinstitutional services, the AI Office is integrated within the\nadministrative framework of a single entity, specifically the DG for Communication\nNetworks, Content, and Technology (DG-CNECT) of the Commission. The AI Office thus\nrepresents primarily a centralised institutional design (see Option 1 above). DG-CNECT\noperates similarly to a national ministry, overseeing the implementation of policies and\nprograms related to the digital single market. Within DG-CNECT, there are multiple units\n(called Connects), each specialising in various facets of digital policy, technology, and\nadministration. These units often have overlapping competencies, and the AI Office\nengages in cross-cutting issues relevant to ",
    "source": "naive",
    "offset": 47
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_48",
    "text": ", each specialising in various facets of digital policy, technology, and\nadministration. These units often have overlapping competencies, and the AI Office\nengages in cross-cutting issues relevant to several of them, with Connect A (‘Artificial\nIntelligence and Digital Industry’) being particularly central.\nIntegrating the AI Office within the DG implies that it operates under the regulations\nand procedural framework of the Commission. However, the AI Office’s precise\norganisational structure, specific method of ensuring expertise, and operational autonomy\nremain ambiguous. No provisions, either in the AIA or in the Commission’s Decision, have\nbeen established regarding the composition of the AI Office, its collaborative dynamics\nwith the various Connects within the DG, or the extent of its operational autonomy. The\nAIA emphasises the necessity for national competent authorities to possess “adequate\n24 It has been established through a Commission’s Decision (Brussels, 24.1.2024, C (202",
    "source": "naive",
    "offset": 48
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_49",
    "text": "s operational autonomy. The\nAIA emphasises the necessity for national competent authorities to possess “adequate\n24 It has been established through a Commission’s Decision (Brussels, 24.1.2024, C (2024) 390 final).\n10\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nTable 2. Structures, compositions, missions, and tasks of the institutional bodies involved in the AIA implementation\nand enforcement\nInstitutional Body\nStructure and Composition\nMission and Tasks\nAI Office (Art. 64 AIA and\nCommission’s Decision)\nCentralised within the DG-\nCNECT of the Commission\n- Harmonise AIA implementation and\nenforcement across the EU\n- Support implementing and delegated\nacts\n- Standardisation and best practices\n- Assist in the establishment and\noperation of regulatory sandboxes\n- Assess and monitor GPAIs and aid\ninvestigations into rule violations\n- Provide administrative support to\nother bodies (Board, Advisory Forum,\nScientific Panel)\n- Consul",
    "source": "naive",
    "offset": 49
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_50",
    "text": "ation of regulatory sandboxes\n- Assess and monitor GPAIs and aid\ninvestigations into rule violations\n- Provide administrative support to\nother bodies (Board, Advisory Forum,\nScientific Panel)\n- Consult and cooperate with\nstakeholders\n- Cooperate with other relevant DG and\nservices of the Commission\n- International cooperation\nAI Board (Art. 65 AIA)\nRepresentatives from each\nMember State, with the AI\nOffice and the European Data\nProtection Supervisor\nparticipating as observers\n- Facilitate consistent and effective\napplication of the AIA\n- Coordinate national competent\nauthorities\n- Harmonise administrative practices.\n- Issue recommendations and opinions\n(upon requests of the Commission)\n- Support the establishment and\noperation of regulatory sandboxes\n- Gather feedback on GPAI-related\nalerts\nAdvisory Forum (Art. 67 AIA)\nStakeholders appointed by the\nCommission\n- Provide technical expertise\n- Prepare opinions and\nrecommendations (upon request of the\nBoard and the Commission)\n- Establish ",
    "source": "naive",
    "offset": 50
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_51",
    "text": "s\nAdvisory Forum (Art. 67 AIA)\nStakeholders appointed by the\nCommission\n- Provide technical expertise\n- Prepare opinions and\nrecommendations (upon request of the\nBoard and the Commission)\n- Establish sub-groups for examining\nspecific questions\n- Prepare an annual report on activities\nScientific Panel (Art. 68 AIA)\nIndependent experts selected by\nthe Commission\n- Support enforcement of AI regulation,\nespecially for GPAI\n- Provide advice on the classification of\nAI models with systemic risk\n- Alert AI Office of systemic risks\n- Develop evaluation tools and\nmethodologies for GPAIs\n- Support market surveillance authorities\nand cross-border activities\nNotifying Authorities\n(Artt. 28-29 AIA)\nDesignated or established by\nMember States\n- Process applications for notification\nfrom conformity assessment bodies\n(CABs)\n- Monitor CABs\n- Cooperate with authorities from other\nMember States\n- Ensure no conflict of interest with\nconformity assessment bodies\n- Conflict of interest prevention and\nassessm",
    "source": "naive",
    "offset": 51
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_52",
    "text": "ment bodies\n(CABs)\n- Monitor CABs\n- Cooperate with authorities from other\nMember States\n- Ensure no conflict of interest with\nconformity assessment bodies\n- Conflict of interest prevention and\nassessment impartiality\n(Continued)\nEuropean Journal of Risk Regulation\n11\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\ntechnical, financial, and human resources, and infrastructure to fulfill their tasks\neffectively, with a sufficient number of personnel permanently available” (Article 70(3)\nAIA), covering expertise areas from data computing to fundamental rights. However, there\nare no equivalent stipulations for the AI Office. This absence is likely justified by the\nexpectation that the AI Office will, at least partially, use the existing infrastructure and\nhuman resources of the DG-CNECT. Nonetheless, expert hiring and substantial funding will\nbe crucial for the success of the Office, an issue that represents a significant challenge for\nthe public sector a",
    "source": "naive",
    "offset": 52
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_53",
    "text": "an resources of the DG-CNECT. Nonetheless, expert hiring and substantial funding will\nbe crucial for the success of the Office, an issue that represents a significant challenge for\nthe public sector as it competes with some of the best-funded private companies on the\nplanet.\nRegarding its operational autonomy, the AI Office is subject to two primary constraints,\naside from its absence of legal personality, which sets it apart from EU agencies. First, its\nincorporation into the administrative structure of DG-CNECT means that DG-CNECT’s\nmanagement plan will guide the AI Office’s strategic priorities and the distribution of\nresources, directly influencing the scope and direction of its initiatives.\nSecond, the operational autonomy of the AI Office is further restricted by the defined\ncompetencies of other entities, including EU bodies, offices, agencies, and national\nauthorities. While it seems appropriate for the AI Office to perform its duties in issuing\nguidance without duplicating the",
    "source": "naive",
    "offset": 53
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_54",
    "text": "cies of other entities, including EU bodies, offices, agencies, and national\nauthorities. While it seems appropriate for the AI Office to perform its duties in issuing\nguidance without duplicating the efforts of relevant Union bodies, offices, and agencies\nunder sector-specific legislation (as per Recital 7 of the Commission’s Decision), the\nmechanisms for coordination remain ambiguous. This ambiguity includes how conflicts or\noverlaps in competencies – e.g., with the European Data Protection Board (EDPB)\nconcerning data quality and management obligations for providers of high-risk systems as\nstipulated by the AIA – will be managed. Consider the development of a healthcare AI\nsystem handling sensitive personal data. Here, the AI Office may emphasise the system’s\ninnovative contributions to healthcare. In contrast, the EDPB might insist on strict\nadherence to GDPR data protection principles, potentially causing tensions in the system’s\ndeployment and usage.\nResolving such discrepancies ",
    "source": "naive",
    "offset": 54
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_55",
    "text": " healthcare. In contrast, the EDPB might insist on strict\nadherence to GDPR data protection principles, potentially causing tensions in the system’s\ndeployment and usage.\nResolving such discrepancies could involve defining the AI Office’s organisational\nstructure\nand\noperational\nscope.\nClarification\ncould\ninclude\nspecifying\nwhether\nTable 2. (Continued )\nInstitutional Body\nStructure and Composition\nMission and Tasks\nNotified Bodies (Artt. 29-38\nAIA)\nA third-party conformity\nassessment body (with legal\npersonality) notified under the\nAIA\n- Verify the conformity of high-risk AI\nsystems\n- Issue certifications\n- Manage and document subcontracting\narrangements\n- Periodic assessment activities (audits)\n- Participate in coordination activities\nand European standardisation\nMarket Surveillance\nAuthorities (Artt. 70–72\nAIA)\nEntities designated or established\nby Member States as single\npoints of contact\n- Non-compliance investigation and\ncorrection for high-risk AI systems\n(e.g., risk measures)\n- ",
    "source": "naive",
    "offset": 55
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_56",
    "text": "rities (Artt. 70–72\nAIA)\nEntities designated or established\nby Member States as single\npoints of contact\n- Non-compliance investigation and\ncorrection for high-risk AI systems\n(e.g., risk measures)\n- Real-world testing oversight and\nserious incident report management\n- Guide and advice on the\nimplementation of the regulation,\nparticularly to SMEs and start-ups\n- Consumer protection and fair\ncompetition support\n12\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\ncollaborative mechanisms exist, such as joint working groups between the AI Office and\nother EU entities or establishing interagency agreements. Such agreements could mirror\nthe Memorandum of Understanding between the European Data Protection Supervisor\n(EDPS) and the European Union Agency for Cybersecurity (ENISA).\nb. Mission(s) and task\nWhile the DG-CNECT pursues a wide range of goals from internet governance to green\ndevelopment, the AI Office’s primary mission, accordi",
    "source": "naive",
    "offset": 56
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_57",
    "text": " Union Agency for Cybersecurity (ENISA).\nb. Mission(s) and task\nWhile the DG-CNECT pursues a wide range of goals from internet governance to green\ndevelopment, the AI Office’s primary mission, according to the Commission Decision, is to\nensure the harmonised implementation and enforcement of the AIA (Article 2, point 1 of\nthe Decision). However, the Decision outlines auxiliary missions: enhancing a strategic and\neffective EU approach to global AI “initiatives”, promoting actions that maximise AI’s\nsocietal and economic benefits, supporting the swift development and deployment of\ntrustworthy AI systems that boost societal welfare and EU competitiveness, and keeping\ntrack of AI market and technology advancements (Article 2, point 2).\nThe language used in the provisions concerning the AI Office tasks, notably in Article 2a,\nis broad and open-ended, referring to contributions to “initiatives on AI” without\nspecifying details. Ambiguity may have been intentional, inviting further interpreta",
    "source": "naive",
    "offset": 57
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_58",
    "text": "ce tasks, notably in Article 2a,\nis broad and open-ended, referring to contributions to “initiatives on AI” without\nspecifying details. Ambiguity may have been intentional, inviting further interpretation.\nOne interpretation is that the AI Office’s role could go beyond the scope of the AIA to\ninclude support for implementing additional AI normative frameworks, such as the revised\nProduct Liability Directive or the Artificial Intelligence Liability Directive (AILD).\nExpanding the AI Office’s remit in this way could be advantageous, as limiting its focus\nto a single regulation might lead to squandering valuable expertise developed through the\nAIA’s implementation. Moreover, broadening the AI Office’s mandate to ensure\nharmonising the AIA’s rules with other AI regulations could prevent conflicts and\ninconsistencies, thereby aiding Member States and their respective authorities in adopting\na comprehensive AI legislative framework. Such an expansion suggests the Office’s\npotential as an eme",
    "source": "naive",
    "offset": 58
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_59",
    "text": "cts and\ninconsistencies, thereby aiding Member States and their respective authorities in adopting\na comprehensive AI legislative framework. Such an expansion suggests the Office’s\npotential as an emerging EU “digital agency”.\nHowever, designating the AI Office as the competent authority for multiple regulatory\nframeworks – with varying tasks depending on the specific framework – points to a\npotential need for restructuring. The AI Office might require future transformation into\na more autonomous body. Without necessarily acquiring legal personality, the AI Office\nmight evolve into an inter-institutional service like the CERT-EU, which could necessitate\ndetaching it from the Commission’s administrative framework.\nThe main issue with transforming the AI Office into an inter-institutional service lies in\nthe inherent design of such services. They are primarily established to offer widespread\nsupport across EU institutions, focusing on internal functionalities such as recruitment\n(via the",
    "source": "naive",
    "offset": 59
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_60",
    "text": "rvice lies in\nthe inherent design of such services. They are primarily established to offer widespread\nsupport across EU institutions, focusing on internal functionalities such as recruitment\n(via the European Personnel Selection Office, EPSO), staff training, promoting inter-\ninstitutional collaboration, and facilitating the efficient execution of legislative and policy\nframeworks. In contrast, the AI Office’s mandate involves spearheading the implementa-\ntion of the AIA, entailing the issuance of guidelines, regulation enforcement, and\ncompliance oversight. Given such entities’ predominantly supportive and non-regulatory\nnature, transitioning into an inter-institutional service might dilute its capability to\nperform these critical functions.\nAgainst this background, a crucial aspect concerning the AI Office is the ambiguity in\nthe current normative framework regarding the breadth of its mission scope. This\nambiguity sets it apart from the European Food Safety Authority (EFSA) or the ",
    "source": "naive",
    "offset": 60
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_61",
    "text": "erning the AI Office is the ambiguity in\nthe current normative framework regarding the breadth of its mission scope. This\nambiguity sets it apart from the European Food Safety Authority (EFSA) or the European\nMedicines Agency (EMA) (in terms of isolation problems) but also opens the door to a\npotentially beneficial interpretation, allowing the AI Office to oversee multiple entities.\nIt is critical to emphasise that adopting this more comprehensive interpretative approach\nwould require appropriate changes in the institutional design to accommodate the Office’s\nextended functions.\nEuropean Journal of Risk Regulation\n13\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nConcerning its specific tasks, the AI Office plays a pivotal role in applying and enforcing\nregulations concerning GPAI, focusing on standardisation efforts to harmonise tools,\nmethodologies, and criteria for evaluating systemic risks associated with GPAI across\nsupranational and national le",
    "source": "naive",
    "offset": 61
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_62",
    "text": "regulations concerning GPAI, focusing on standardisation efforts to harmonise tools,\nmethodologies, and criteria for evaluating systemic risks associated with GPAI across\nsupranational and national levels. It also monitors GPAIs continuously for adherence to\nstandards and potential new risks, supports investigations into GPAI violations, and assists\nin developing delegated acts and regulatory sandboxes for all AI systems under the AIA.\nThe responsibilities assigned to the AI Office are broadly defined, with the expectation\nthat their precise implementation will evolve based on practical experience. The AI Office\nrequires significant expertise and financial resources to offer support and technical advice\nacross diverse tasks and AI systems. Achieving this will demand a robust administrative\nframework that effectively manages internal subgroup coordination and external\nengagements with supranational and national entities.\nAn important aspect to consider within the operational scope of th",
    "source": "naive",
    "offset": 62
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_63",
    "text": "\nframework that effectively manages internal subgroup coordination and external\nengagements with supranational and national entities.\nAn important aspect to consider within the operational scope of the Office is the nature\nof its decisions. The AI Office does not issue binding decisions on its own. Instead, it\nprovides support and advice to the Commission. Nonetheless, it plays a role in formulating\nthe Commission’s decisions, including implementing and delegated acts, which, while non-\nlegislative, are binding across all Member States. These decisions by the Commission can\nbe challenged based on various grounds, such as exceeding its authority or misusing its\npowers, and through specific processes before and after they are formally adopted. For\nexample, before adoption, implementing and delegated acts can be contested through\nfeedback mechanisms provided by committees (as part of the comitology) or by EU\ninstitutions; once adopted, these acts are subject to judicial review by the Cour",
    "source": "naive",
    "offset": 63
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_64",
    "text": "elegated acts can be contested through\nfeedback mechanisms provided by committees (as part of the comitology) or by EU\ninstitutions; once adopted, these acts are subject to judicial review by the Court of Justice\nof the EU, which assesses their compliance with the foundational legislation.25\nHowever, the effectiveness of mechanisms for appealing decisions may be compromised\nby the opaque nature of the AI Office’s support to the Commission, its interactions\nwithin DG-CNECT, and its relationships with external bodies, such as national authorities.\nSuch opacity can obscure the reasons behind certain implementing or delegated acts,\nwhich is particularly concerning given the AI Office’s engagement with external experts\nand stakeholders.26 Accordingly, the documentation and disclosure of the AI Office’s\ncontributions, as evidenced through summary records in the comitology register and the\nexplanatory memoranda accompanying the Commission’s delegated acts, become crucial.\nIV.2. The AI Board, ",
    "source": "naive",
    "offset": 64
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_65",
    "text": "Office’s\ncontributions, as evidenced through summary records in the comitology register and the\nexplanatory memoranda accompanying the Commission’s delegated acts, become crucial.\nIV.2. The AI Board, the Advisory Forum, and the Scientific Panel\nThe European Artificial Intelligence Board (hereafter “the Board”) is distinct from the AI\nOffice. Yet, it undertakes tasks that are parallel and intersect with those of the AI Office,\nparticularly in supervising and directing the execution of the AIA. Currently, the\ngovernance and operational structure of the Board is primarily detailed in Articles 65 and\n66 of the AIA. In addition to the Board, the AIA also establishes other bodies that, while\nindependent in their formation, support the Board: the Advisory Forum and the Scientific\nPanel. The result is a complex network of bodies, making their coordination challenging.\na. Structures, roles, and composition of the three bodies\nThe Board consists of a representative from each Member State, appoin",
    "source": "naive",
    "offset": 65
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_66",
    "text": "t is a complex network of bodies, making their coordination challenging.\na. Structures, roles, and composition of the three bodies\nThe Board consists of a representative from each Member State, appointed for three years,\nwith one of them as the chair. The AI Office and the European Data Protection Supervisor\nparticipate as observers without voting powers. Unlike the generic recruitment criteria for\n25 R Dehousse, “Comitology: Who Watches the Watchmen?” (2003) 10 Journal of European Public Policy 798;\nBrandsma and Blom-Hansen (n 14).\n26 This also emerges from the published call for interests: https://digital-strategy.ec.europa.eu/en/policies/\nai-office.\n14\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nthe AI Office, the AIA explicitly requires that Member States appoint representatives to the\nBoard who have the requisite expertise and authority in their respective countries to\ncontribute to the Board’s missions effectively. The",
    "source": "naive",
    "offset": 66
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_67",
    "text": "tly requires that Member States appoint representatives to the\nBoard who have the requisite expertise and authority in their respective countries to\ncontribute to the Board’s missions effectively. These representatives are also empowered\nto gather essential data and information to ensure uniformity and coordination among\nnational competent authorities (Article 65(4)(c) AIA). Coordination is supported by two\npermanent sub-groups, which serve as platforms for collaboration and information\nsharing between market surveillance and notifying authorities. Additionally, the Board has\nthe authority to form temporary sub-groups to delve into other specific topics.27\nThe Board may invite other authorities or experts on a case-by-case basis. However, it\nwill be supported by an Advisory Forum (hereafter “the Forum”), which provides technical\nexpertise also to the Commission (Article 67 AIA). The Commission will ensure the Forum\nincludes diverse stakeholders, such as industry representatives, start-",
    "source": "naive",
    "offset": 67
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_68",
    "text": "r “the Forum”), which provides technical\nexpertise also to the Commission (Article 67 AIA). The Commission will ensure the Forum\nincludes diverse stakeholders, such as industry representatives, start-ups, small and\nmedium-sized enterprises (SMEs), civil society groups, and academic institutions, to offer\ncomprehensive stakeholder feedback to the Commission and the Board.\nFinally, the AIA mandates the creation of a Scientific Panel of independent experts\n(hereafter “the Panel”) through a Commission implementing act, aimed at bolstering the\nAIA’s enforcement activities (Article 68 AIA). In consultation with the Board, the\nCommission will determine the Panel’s membership, selecting experts based on their\nspecialised knowledge and independence from AI system providers. The Panel is designed\nto be a resource for Member States and assist them in enforcing the AIA. It should be noted\nthat Member States may need to pay fees for the expert advice and support provided by\nthe Panel (Article 69 AI",
    "source": "naive",
    "offset": 68
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_69",
    "text": " be a resource for Member States and assist them in enforcing the AIA. It should be noted\nthat Member States may need to pay fees for the expert advice and support provided by\nthe Panel (Article 69 AIA).\nWithin the EU’s regulatory framework for AI, the AI Board operates as an advisory body,\nthe Advisory Forum acts as a consultative body offering industry insights to both the Board\nand the Commission, and the Scientific Panel primarily provides expert scientific support\nto the AI Office and the Member States in need of its specialised knowledge. The\ncomposition of these entities varies: the members of the AI Board are appointed by\nMember States, and the Commission and the Board choose the Advisory Forum’s members.\nIn contrast, the Scientific Panel’s members are appointed solely by the Commission.\nDespite the distinct tasks assigned to them, which will be discussed later, the necessity\nof having three separate entities with pretty similar compositions raises questions. The AI\nBoard’s est",
    "source": "naive",
    "offset": 69
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_70",
    "text": "ssion.\nDespite the distinct tasks assigned to them, which will be discussed later, the necessity\nof having three separate entities with pretty similar compositions raises questions. The AI\nBoard’s establishment is understandable for ensuring representation and coordination\namong Member States and maintaining some independence from EU institutions, without\nrequiring members to possess scientific expertise. However, the rationale behind keeping\nthe Advisory Forum and the Scientific Panel is not apparent. The Advisory Forum is\nintended to draw upon the diverse perspectives of civil society and industry sectors,\nessentially acting as an institutionalised form of lobbying to represent their varying\ncommercial interests. However, it must also ensure a balance with non-commercial\ninterests. In contrast, the Scientific Panel consists of independent and (hopefully) unbiased\nacademic experts with specific tasks related to GPAIs.\nb. Mission(s) and tasks: Ockham’s razor\nThe three bodies are set to",
    "source": "naive",
    "offset": 70
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_71",
    "text": "ntrast, the Scientific Panel consists of independent and (hopefully) unbiased\nacademic experts with specific tasks related to GPAIs.\nb. Mission(s) and tasks: Ockham’s razor\nThe three bodies are set to perform slightly different tasks. The Board undertakes\nnumerous tasks (Article 66 AIA), such as providing guidance and support to the\nCommission and Member States to coordinate national authorities. It offers recom-\nmendations for delegated and implementing acts and aims to standardise administrative\npractices across Member States, for instance, through addressing exemptions from\nconformity assessment procedures and by supporting the operation of regulatory\n27 The AIA has outlined initial functions and roles for the Board, yet additional details and responsibilities are\nexpected to be further delineated in subsequent legislation.\nEuropean Journal of Risk Regulation\n15\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nsandboxes (Article 66(d) AIA). Addition",
    "source": "naive",
    "offset": 71
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_72",
    "text": " delineated in subsequent legislation.\nEuropean Journal of Risk Regulation\n15\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nsandboxes (Article 66(d) AIA). Additionally, the Board advises on creating codes of conduct\nand applying harmonised standards, supports the AI Office in helping national authorities\nestablish and enhance regulatory sandboxes, and gathers feedback from Member States on\nalerts related to GPAIs.\nNote that, other than the European Data Protection Board under Article 65 GDPR, the AI\nBoard does not have the authority to revise national supervisory agency decisions or\nresolve disputes between national authorities with binding force. Under the GDPR, this has\nemerged as a critical mechanism, particularly in dealing with the contentious ruling of the\nIrish Data Protection Commission concerning big technology companies headquartered in\nIreland.28 This lack of a corresponding authority for the AI Board may prove a distinct\ndisadvantage, hi",
    "source": "naive",
    "offset": 72
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_73",
    "text": "ng of the\nIrish Data Protection Commission concerning big technology companies headquartered in\nIreland.28 This lack of a corresponding authority for the AI Board may prove a distinct\ndisadvantage, hindering the uniform application of the law, if some Member States\ninterpret the AIA in highly idiosyncratic fashions (as the Irish Data Protection Commission\ndid with the GDPR). In this context, one may particularly think of the supervision of the\nlimitations enshrined in Article 5 AIA on surveillance tools using remote biometric\nidentification. European oversight may be required, especially in countries with significant\ndemocratic backsliding, to avoid the abuse of AI for stifling legitimate protest and\nestablishing an illiberal surveillance regime.\nThe Board and Office collaboration will be characterised by mutual support. However,\nwhile there are areas where the functions of the AI Board and the AI Office might seem to\noverlap, especially from the viewpoint of Member States, merging the",
    "source": "naive",
    "offset": 73
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_74",
    "text": "characterised by mutual support. However,\nwhile there are areas where the functions of the AI Board and the AI Office might seem to\noverlap, especially from the viewpoint of Member States, merging these two entities is not\nviable. The need for political representation and their distinct roles – where the Board\nprovides advisory insights and the Office executes the Commission’s binding decisions –\nprevents such a merger.\nSimilarly, the roles of the Advisory Forum and the Scientific Panel might not be\ndistinctly demarcated. The Advisory Forum has a broad mandate to provide advice and\nexpertise to the Board and the Commission, supporting various tasks under the AIA.\nThe Scientific Panel advises and supports the AI Office, specifically on implementing\nand enforcing the AIA, focusing on GPAIs. Its tasks include developing evaluation tools,\nbenchmarks, and methodologies for GPAIs, advising on classifying GPAIs with systemic\nrisks, and assisting Member States in their enforcement activities a",
    "source": "naive",
    "offset": 74
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_75",
    "text": "Its tasks include developing evaluation tools,\nbenchmarks, and methodologies for GPAIs, advising on classifying GPAIs with systemic\nrisks, and assisting Member States in their enforcement activities as requested\n(Article 68 AIA).\nHowever, the distinction between the Advisory Forum and the Scientific Panel seems\nless precise than the separation between the Board and the Office. Questions arise\nregarding the exclusivity of the Forum’s support to the Board and the Commission and\nwhether the Panel’s specialised GPAI expertise could benefit these entities. If the\noverarching aim of the AIA’s governance structure is to secure impartial and external\nfeedback for the comprehensive implementation and enforcement, then such support\nshould be accessible to all EU institutional bodies involved – namely, the Commission and\nits Office – as well as to Member States, whether through the Board or their respective\nnational authorities. While it might be argued that the AI Office’s participation in Board",
    "source": "naive",
    "offset": 75
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_76",
    "text": "y, the Commission and\nits Office – as well as to Member States, whether through the Board or their respective\nnational authorities. While it might be argued that the AI Office’s participation in Board\nmeetings is an indirect channel for the Panel’s expertise to influence broader discussions,\nthis arrangement is not entirely satisfactory. The indirect nature of this influence means\nthat the Panel’s specialised opinions could become less impactful, especially since the AI\nOffice’s contributions to the Board’s meetings lack formal voting power, which could\nfurther dilute the Panel’s input. In any case, the fact that the Panel’s insights are indirectly\npresented to the Board is an a fortiori argument against the continued separation of the\nAdvisory Forum and the Scientific Panel. If the separation was meant to distinguish the\n28 R Boardman, “Key Takeaways from the Irish DPC and EDPB Decisions on Facebook Data Transfers, DPC\nDecision, EU User Data” Bird&Bird (23 May 2023) <https://www.twobi",
    "source": "naive",
    "offset": 76
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_77",
    "text": "tion was meant to distinguish the\n28 R Boardman, “Key Takeaways from the Irish DPC and EDPB Decisions on Facebook Data Transfers, DPC\nDecision, EU User Data” Bird&Bird (23 May 2023) <https://www.twobirds.com/en/insights/2023/global/key-ta\nkeaways-from-the-irish-dpc-and-edpb-decisions-on-facebook-data-transfers> (accessed 29 March 2024).\n16\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\ntypes of support provided by each entity, indirect participation blurs these lines. This topic\nwill be expanded upon in section VI.\nV. National authorities: Notifying authorities, notified bodies, and market\nsurveillance authorities\nSupranational authorities have an essential role, but the effective implementation and\nenforcement of this Regulation frequently require a local presence, placing the\nresponsibility primarily on Member States. Each is expected to set up at least one\nnotifying authority responsible for compliance and certification proc",
    "source": "naive",
    "offset": 77
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_78",
    "text": "requently require a local presence, placing the\nresponsibility primarily on Member States. Each is expected to set up at least one\nnotifying authority responsible for compliance and certification processes and one market\nsurveillance authority to verify that products meet EU harmonisation legislation standards\nfor safety, health, and environmental protection as outlined in Regulation (EU) 2019/\n1020.29 Both authorities are also encouraged to guide compliance to SMEs and start-ups,\nconsidering any relevant recommendations from the Board and the Commission (Chapter\nVII, Section 2 AIA).\nThe AIA mandates that national authorities must have permanently available staff with\nexpertise in AI, data protection, cybersecurity, fundamental rights, health and safety, and\nrelevant standards and laws.30 Member States must assess and report this adequacy to the\nCommission every two years (Article 70 AIA). Such a requirement illustrates how EU policy\nregulations can include an organiaational component ",
    "source": "naive",
    "offset": 78
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_79",
    "text": "Member States must assess and report this adequacy to the\nCommission every two years (Article 70 AIA). Such a requirement illustrates how EU policy\nregulations can include an organiaational component that interacts with the historical\nprerogatives of national governments to structure the state apparatus at its own will\n(“administrative sovereignty”).\nIn this context, Member States have the flexibility to design their governance\nstructures for AI regulation: they can either establish new regulatory bodies dedicated to\nAI or integrate these oversight responsibilities into existing entities, like national Data\nProtection Authorities, within their legal frameworks. The autonomy of Member States in\nthis context enables them to delegate tasks to the most suitable public organisations, as\ndiscussed above (Part II.b)).\nV.1. Notifying authority and notified bodies\nNotifying authorities are national entities established by each Member State to evaluate,\ndesignate, and recognise conformity assess",
    "source": "naive",
    "offset": 79
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_80",
    "text": "ed above (Part II.b)).\nV.1. Notifying authority and notified bodies\nNotifying authorities are national entities established by each Member State to evaluate,\ndesignate, and recognise conformity assessment bodies and oversee their activities (Article\n28 AIA).\nEntities seeking to perform conformity assessments under the AIA must apply to the\nnotifying authority in their Member State or a third country, providing a detailed\ndescription of their assessment activities, used modules, AI systems competencies, and an\naccreditation certificate from a national body. Once an applicant is verified to meet all\ncriteria, the notifying authority endorses it as a notified body, officially recognised to\nevaluate AI system conformity before market release. Notifying authorities oversee these\nbodies impartially, are prohibited from engaging in assessment activities to avoid conflicts\nof interest, and can restrict, suspend, or withdraw a body’s status if it fails to meet\nobligations.\nNotified bodies are r",
    "source": "naive",
    "offset": 80
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_81",
    "text": "lly, are prohibited from engaging in assessment activities to avoid conflicts\nof interest, and can restrict, suspend, or withdraw a body’s status if it fails to meet\nobligations.\nNotified bodies are responsible for impartially and confidentially assessing high-risk AI\nsystems. They ensure that these meet regulatory standards and possess the necessary\nexpertise, including for outsourced work. They have the right to unrestricted access to\nrelevant datasets and may request additional testing to confirm compliance. Upon a\n29 This Regulation’s market surveillance targets products under Union harmonisation listed in Annex I,\nexcluding food, feed, medicines, live plants and animals, and reproduction-related products.\n30 The operational details for notifying authorities and notified bodies are specified in Chapter 4, Title III of the\nAIA, and guidelines for notifying and market surveillance authorities are in Title VI, Chapter 2 (‘Governance’).\nEuropean Journal of Risk Regulation\n17\nhttps://do",
    "source": "naive",
    "offset": 81
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_82",
    "text": "cified in Chapter 4, Title III of the\nAIA, and guidelines for notifying and market surveillance authorities are in Title VI, Chapter 2 (‘Governance’).\nEuropean Journal of Risk Regulation\n17\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nsatisfactory assessment, they issue an EU technical documentation assessment certificate,\nvalid for up to five years, depending on the AI system category. Notified bodies must justify\ntheir certification decisions, which can be appealed by providers, and are required to\ninform authorities about their certification decisions and significant operational changes,\nfostering transparency and accountability in the AI certification process.\nThe regulatory framework governing the structure and operations of notifying\nauthorities and notified bodies looks robust. It is also, to an extent, tried and tested as\nnotified bodies of the European Medicines Agency are also accredited to conduct\nconformity assessments for medical devic",
    "source": "naive",
    "offset": 82
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_83",
    "text": "and notified bodies looks robust. It is also, to an extent, tried and tested as\nnotified bodies of the European Medicines Agency are also accredited to conduct\nconformity assessments for medical devices. However, it still falls short in terms of\nspecificity, particularly regarding the mechanisms to ensure their impartiality and\nprevent conflicts of interest (also indirect ones). Impartiality is crucial for upholding the\nintegrity of the conformity assessment process. The AIA stipulates that notifying\nauthorities must be organised and function to avoid conflicts of interest with conformity\nassessment bodies (Article 30 AIA). However, it lacks detailed guidance on the\nimplementation of such measures. It does not explicitly designate who is responsible\nfor enforcing these requirements – as instead does with the AI Office for the Scientific\nPanel (Article 68 AIA) – particularly regarding establishing effective oversight mechanisms\nlike regular audits. While the supervision conducted by acc",
    "source": "naive",
    "offset": 83
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_84",
    "text": "stead does with the AI Office for the Scientific\nPanel (Article 68 AIA) – particularly regarding establishing effective oversight mechanisms\nlike regular audits. While the supervision conducted by accreditation bodies does provide\nsome level of oversight, focusing mainly on the competence and compliance with quality\nstandards (such as ISO) of the notified bodies, these controls may not be comprehensive\nenough. They tend to concentrate on these bodies’ technical competencies and quality\nmanagement systems rather than addressing the broader issues of ensuring impartiality\nand avoiding conflicts of interest.\nLiterature raises two main concerns about notified bodies. First, there is a lack of\norganisational and operational transparency, a situation worsened by these bodies\nfrequently outsourcing their tasks.31 Second, there are significant concerns about the\nneutrality of these notified bodies due to their financial relationships with AI providers.\nThese relationships, which can involve fe",
    "source": "naive",
    "offset": 84
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_85",
    "text": "ng their tasks.31 Second, there are significant concerns about the\nneutrality of these notified bodies due to their financial relationships with AI providers.\nThese relationships, which can involve fees or commissions, might compromise their\ndecision-making, casting doubt on their ability to regulate effectively.32\nAnother critical aspect requiring attention is the coordination among notified bodies\n(Article 38 AIA) to prevent divergent interpretations and applications of EU directives and\nregulations by Member States. Divergences could lead to inconsistencies in how notified\nbodies are designated and monitored in different jurisdictions. This situation echoes\nchallenges observed in other sectors, such as healthcare, where drugs and devices not\napproved in one region may seek approval in another. Ultimately, “conformity shopping”\nmust be prevented. Thus, refining and clarifying the regulations concerning the\nimpartiality and oversight of notified bodies is a critical challenge that the",
    "source": "naive",
    "offset": 85
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_86",
    "text": "nother. Ultimately, “conformity shopping”\nmust be prevented. Thus, refining and clarifying the regulations concerning the\nimpartiality and oversight of notified bodies is a critical challenge that the existing\nregulatory framework needs to address more thoroughly.\nV.2. Market surveillance authority\nUnder the AIA, Member States are mandated to appoint a specific Market Surveillance\nAuthority (MSA) to serve as a single point of contact (Art. 70 AIA) and to communicate the\ndesignated point of contact to the Commission. Following this, the Commission will\nprovide a list of the single points of contact available to the public.\nIn the EU, market surveillance ensures that products meet health and safety standards,\nsupporting consumer protection and fair competition through inspections, document\n31 J-P Galland, “The Difficulties of Regulating Markets and Risks in Europe through Notified Bodies” (2013)\n4 European Journal of Risk Regulation 365.\n32 A Cefaliello and M Kullmann, “Offering False Se",
    "source": "naive",
    "offset": 86
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_87",
    "text": "1 J-P Galland, “The Difficulties of Regulating Markets and Risks in Europe through Notified Bodies” (2013)\n4 European Journal of Risk Regulation 365.\n32 A Cefaliello and M Kullmann, “Offering False Security: How the Draft Artificial Intelligence Act Undermines\nFundamental Workers Rights” (2022) 13 European Labour Law Journal 542.\n18\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nreviews, and compliance tests. An EU-wide product compliance network facilitates\nadherence to standards by encouraging collaboration and information sharing among\nMember States and customs authorities to uphold product safety and integrity.33\nUnder the AIA, MSAs have enhanced powers to oversee high-risk AI systems,\nparticularly those used in law enforcement. These powers include accessing processed\npersonal data, relevant information, and, if necessary, AI system source codes to verify\ncompliance. MSAs can also bypass standard assessment procedures unde",
    "source": "naive",
    "offset": 87
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_88",
    "text": ". These powers include accessing processed\npersonal data, relevant information, and, if necessary, AI system source codes to verify\ncompliance. MSAs can also bypass standard assessment procedures under exceptional\ncircumstances, such as threats to public security or health, and are involved in real-world\ntesting, managing incident reports, and enforcing risk mitigation measures for compliant\nAI systems that still pose public threats. The Commission coordinates these efforts through\nthe AI Office. MSAs act as central contact points for administrative and public inquiries\nfacilitated by the EUGO network within the digital e-government platform framework.\nFurthermore, Market Surveillance Authorities (MSAs) are tasked with liaising with\nnational public authorities responsible for ensuring compliance with Union laws that\nprotect fundamental rights, including non-discrimination principles, such as national data\nprotection authorities. The AIA grants these authorities the right to demand and ",
    "source": "naive",
    "offset": 88
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_89",
    "text": "liance with Union laws that\nprotect fundamental rights, including non-discrimination principles, such as national data\nprotection authorities. The AIA grants these authorities the right to demand and access\nany relevant documentation maintained under the regulation in a format that is accessible\nand comprehensible (Article 77 AIA). The right to access must be granted when these\nauthorities must effectively carry out their duties within their legal scope. When such\ndocumentation is requested, the relevant public authority or body must notify the\ncorresponding MSA in the Member State involved.\nA key question regarding MSAs is their institutional design. Article 70 of the AIA allows\nMember States flexibility in establishing or integrating new authorities into existing ones.\nIn practice, the design choice may be contingent on pre-existing administrative structures\nof MSAs (see Part 2b). Currently, EU Member States possess various authorities categorised\nby sector (e.g., Medical Devices, Co",
    "source": "naive",
    "offset": 89
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_90",
    "text": "esign choice may be contingent on pre-existing administrative structures\nof MSAs (see Part 2b). Currently, EU Member States possess various authorities categorised\nby sector (e.g., Medical Devices, Construction Products, Motor Vehicles) listed on the\nCommission portal.34 One approach to minimise the creation of new authorities would\nbe establishing dedicated sub-sections within existing MSAs, granting them exclusive\ncompetence over AI used in their specific sectors. However, this strategy might not be\nsufficient in the long run. Considering the anticipated growth in AI functionalities and (EU)\nlegislation, a dedicated MSA for AI products and services will likely be more appropriate,\nwith the three options discussed above ranging from an entirely new agency to a\n“competence center” within an existing one (Part 2b).\nThe AIA also remains unclear on whether users or third parties negatively impacted by\nAI systems will have the right to complain to MSAs. The GDPR grants individuals the righ",
    "source": "naive",
    "offset": 90
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_91",
    "text": "n existing one (Part 2b).\nThe AIA also remains unclear on whether users or third parties negatively impacted by\nAI systems will have the right to complain to MSAs. The GDPR grants individuals the right\nto file complaints and seek judicial remedies against supervisory authorities. The absence\nof a similar right for AI-related grievances under the AIA would undermine its safeguard of\naccess to justice.35\nAnother critical aspect regards the need for harmonisation among various MSAs, with a\nspecific concern about disparities in resource allocation by Member States. The AIA\nunderscores the importance of equipping national competent authorities with sufficient\ntechnical, financial, and human resources (Article 70(3) AIA). However, discrepancies in the\nprovision of these resources across Member States can lead to uneven enforcement and\noversight, with implications for market growth and innovation. A prime example of this is\n33 Regulation (EU) 2019/1020 is the cornerstone of the legal framewor",
    "source": "naive",
    "offset": 91
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_92",
    "text": "tates can lead to uneven enforcement and\noversight, with implications for market growth and innovation. A prime example of this is\n33 Regulation (EU) 2019/1020 is the cornerstone of the legal framework governing market surveillance authorities\nin the European Union. It replaces the earlier market surveillance provisions outlined in Regulation (EC) No 765/\n2008. However, other relevant regulations also play a part, such as Decision 768/2008/EC and Directive 2001/95/EC.\n34 https://single-market-economy.ec.europa.eu/single-market/goods/building-blocks/market-surveillance/\norganisation_en.\n35 M Fink, “The EU Artificial Intelligence Act and Access to Justice” <https://hdl.handle.net/1887/3180727>\n(accessed 30 April 2024).\nEuropean Journal of Risk Regulation\n19\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nthe potential delay in product investigations. A lack of sufficient resources at MSAs can\nsignificantly slow the regulatory oversight of emerging AI te",
    "source": "naive",
    "offset": 92
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_93",
    "text": "7 Published online by Cambridge University Press\nthe potential delay in product investigations. A lack of sufficient resources at MSAs can\nsignificantly slow the regulatory oversight of emerging AI technologies. For start-ups and\ncompanies driven by innovation, the speed at which they can enter the market is crucial.\nAgainst this background, it is necessary to strengthen existing coordination\nmechanisms within the EU, such as the EU Product Compliance Network (EUPCN),\nestablished by the Market Surveillance Regulation (2019/1020). Comprising representa-\ntives from each EU country, the EUPCN aims to facilitate the identification of shared\npriorities for market surveillance activities and the cross-sectoral exchange of information\non product evaluations. This includes risk assessment, testing methods and outcomes, and\nother factors pertinent to control activities. It also focuses on the execution of national\nmarket surveillance strategies and actions. Such enhanced coordination is vital f",
    "source": "naive",
    "offset": 93
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_94",
    "text": " methods and outcomes, and\nother factors pertinent to control activities. It also focuses on the execution of national\nmarket surveillance strategies and actions. Such enhanced coordination is vital for\nmitigating disparities in resource availability and ensuring a more uniform approach to\nthe regulation and oversight of AI technologies across the EU. To conclude this section, in\nFigure 1, we provide a visual representation to delineate the principal genetic (indicated\nby a bold line) and functional (represented by a thin line) connections among the\ninstitutional entities engaged in executing and enforcing the AIA.\nVI. Towards simplified and robust governance: recommendations\nBuilding on this analysis, we envision several important updates that should be made to\nthe governance structure of the AI Act.\nVI.1. Clarifying the institutional design of the AI Office\nGiven the broad spectrum of tasks anticipated for the AI Office – from evaluating GPAIS’\ncapabilities to assisting in creating r",
    "source": "naive",
    "offset": 94
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_95",
    "text": " the AI Act.\nVI.1. Clarifying the institutional design of the AI Office\nGiven the broad spectrum of tasks anticipated for the AI Office – from evaluating GPAIS’\ncapabilities to assisting in creating regulatory sandboxes – more detailed organisational\nguidance seems needed to identify its institutional design. Additionally, the mandate for\nthe AI Office to “involve independent experts to carry out evaluations on its behalf”\n(Recital 164 AIA) lacks specificity concerning the criteria for selecting these experts.\nA more structured approach, similar to the UK’s model for health technology assessments\nFigure 1. Supranational and national bodies involved in the implementation and enforcement of the AIA.\n20\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nwhere the National Institute for Health and Care Excellence (NICE) sets precise criteria for\nevidence evaluation and commissions independent reviews from entities like the Cochrane\nCol",
    "source": "naive",
    "offset": 95
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_96",
    "text": "niversity Press\nwhere the National Institute for Health and Care Excellence (NICE) sets precise criteria for\nevidence evaluation and commissions independent reviews from entities like the Cochrane\nCollaborative, could inform the AI Office’s procedures. This model, supported by\ngovernment funding, provides a structured and standardised method that could inform\nthe AI Office’s procedures to ensure its effectiveness in fulfilling its diverse responsibilities.\nAnother critical consideration is the potential impact of integrating the AI Office within\nthe overarching framework of the Commission, which may obscure its operational\ntransparency. Concern stems from the obligation to adhere to the Commission’s general\npolicies on communication and confidentiality. For example, the right to public access to\nCommission documents, governed by Regulation (EC) No 1049/2001, includes numerous\nexceptions that could impede the release of documents related to the AI Office. One such\nexception allows EU in",
    "source": "naive",
    "offset": 96
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_97",
    "text": "ess to\nCommission documents, governed by Regulation (EC) No 1049/2001, includes numerous\nexceptions that could impede the release of documents related to the AI Office. One such\nexception allows EU institutions to deny access to records if it would compromise the\n“[ : : : ] commercial interests of a natural or legal person, including intellectual property,”\na broadly defined provision lacking specific, enforceable limits. To mitigate this risk,\napplying a narrower interpretation of these exceptions to the AI Office would align with\nrecent trends in the case law of the EU Courts,36 helping to avoid transparency issues\nsimilar to those faced by other EU agencies, such as Frontex.37\nFurthermore, greater clarity regarding the AI Office’s operational autonomy is needed.\nFor example, guidelines delineating its decision-making authority, financial independence\nand engagement capabilities with external parties would be beneficial. As described\npreviously (Recital 14), the call for involving in",
    "source": "naive",
    "offset": 97
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_98",
    "text": "delineating its decision-making authority, financial independence\nand engagement capabilities with external parties would be beneficial. As described\npreviously (Recital 14), the call for involving independent experts is a step in the right\ndirection. Still, detailed criteria for expert selection and involvement are required to\nensure transparency and efficacy in its evaluation and advisory roles.\nAn alternative, potentially more effective approach would be establishing the AI Office\nas a decentralised agency with its legal identity, like the EFSA and the EMA.\nDecentralisation, designed for pivotal sectors within the single market, would endow\nthe AI Office with enhanced autonomy, including relative freedom from political agendas\nat the Commission level, a defined mission, executive powers, and the authority to issue\nbinding decisions, albeit with options for appeal and judicial scrutiny. Such an\norganisational shift would likely boost the AI Office’s independence from the\nCommission a",
    "source": "naive",
    "offset": 98
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_99",
    "text": ", and the authority to issue\nbinding decisions, albeit with options for appeal and judicial scrutiny. Such an\norganisational shift would likely boost the AI Office’s independence from the\nCommission and the broader EU institutional matrix, positioning it as a key player in\nAI governance. However, this change could lead to agency drift, where operations by the AI\nOffice conflict with the wishes or strategies of the Commission. However, empirical\nevidence suggests that the main interlocutors of EU agencies are “parent” Commission\nDGs. Therefore, despite adopting a decentralised agency format, the AI Office will likely\nsustain a strong relationship with the Commission.38 Empirical studies suggest that one\neffective mitigation strategy against agency drift is establishing organisational units\nwithin the Commission that duplicate or overlap those of the agency.39 This increases the\norganisational capacities and expertise within the Commission to oversee and control\nthe agency.\nThe decentral",
    "source": "naive",
    "offset": 99
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_100",
    "text": "within the Commission that duplicate or overlap those of the agency.39 This increases the\norganisational capacities and expertise within the Commission to oversee and control\nthe agency.\nThe decentralised alternative still carries inherent risks and challenges. A notable\nconcern is the potential for the AI Office to become somewhat isolated from the rest of the\nEU institutional ecosystem, which could undermine the effectiveness of its supervision and\ndiminish the capacity for cohesive, EU-wide responses and strategies concerning AI\n36 A Marcoulli and L Cappelletti, “Recent Trends and Developments in the Case Law of EU Courts on Access to\nDocuments” (2023) 23 ERA Forum 477.\n37 L Salzano and M Gkliati, “Mysteriousness by Design: The Case of Frontex and the Regulation on Public Access\nto Documents” (30 September 2023) <https://papers.ssrn.com/abstract=4588534> (accessed 23 February 2024).\n38 Egeberg and Trondal (n 5).\n39 M Egeberg and J Trondal, “Political Leadership and Bureaucratic Auto",
    "source": "naive",
    "offset": 100
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_101",
    "text": "ments” (30 September 2023) <https://papers.ssrn.com/abstract=4588534> (accessed 23 February 2024).\n38 Egeberg and Trondal (n 5).\n39 M Egeberg and J Trondal, “Political Leadership and Bureaucratic Autonomy: Effects of Agencification” (2009)\n22 Governance 673.\nEuropean Journal of Risk Regulation\n21\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nregulation. A similar concern is the potential for this isolation to be used strategically to\nlimit workload by, for example, declaring only “pure AI” within the AI Office’s remit and\nany AI tool embedded or interacting with non-AI components outside of scope. Moreover,\nthis structure amplifies concerns related to “agencification,” a term critics use to describe\nthe risks of granting regulatory bodies excessive but not complete autonomy in practice\nsince these are agencies designed as units subordinated to ministry-like institutions in\ngovernment systems. Such autonomy could lead to their actions diverging from,",
    "source": "naive",
    "offset": 101
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_102",
    "text": "not complete autonomy in practice\nsince these are agencies designed as units subordinated to ministry-like institutions in\ngovernment systems. Such autonomy could lead to their actions diverging from, or\ncomplicating, the EU’s overarching objectives and governance frameworks. Critics argue\nthat this could result in a democratic legitimacy deficit or undermine the principles that\nguide how the EU operates and delegates its powers.40 To mitigate the risks associated with\nagencification, implementing more robust ex-ante and ex-post evaluation mechanisms for\nagency performance is advisable (as we suggest in recommendation (d)). These\nevaluations, maybe conducted periodically by the European Commission, would assess\nthe impact of agency actions and regulations, ensuring alignment with EU objectives and\nprinciples. A complimentary, or alternative, mitigation strategy would be to establish\norganisational duplication and overlap within the Commission, as outlined above.\nVI.2. Integrating the F",
    "source": "naive",
    "offset": 102
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_103",
    "text": "ives and\nprinciples. A complimentary, or alternative, mitigation strategy would be to establish\norganisational duplication and overlap within the Commission, as outlined above.\nVI.2. Integrating the Forum and the Panel into a single body\nThe first point concerns the institutional framework of the advisory bodies and\nstakeholder representation in them. As anticipated, there is potential for consolidating the\nPanel and the Forum into a singular entity. Integrating them would reduce duplications\nand bolster the deliberation process before reaching a decision. A combined entity would\nmerge the diverse knowledge bases of civil society, the business sector, and the academic\ncommunity, promoting inclusive and reflective discussions of the needs identified by the\nCommission and Member States. A unified entity combining the Advisory Forum’s\nextensive stakeholder engagement with the Scientific Panel’s specialised, independent\nexpertise could significantly improve the quality of advice to the Boa",
    "source": "naive",
    "offset": 103
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_104",
    "text": "ified entity combining the Advisory Forum’s\nextensive stakeholder engagement with the Scientific Panel’s specialised, independent\nexpertise could significantly improve the quality of advice to the Board, the Office, and\nother EU institutions or agencies. The unified entity would ensure that the guidance\nreflects both the technical complexities and societal implications of AI and challenges the\nbelief that GPAI necessitates fundamentally different knowledge from other AI systems.\nSubcommittees or working groups could help avoid the risk of this unified body becoming\noverburdened or diluting specific expertise within a larger group.\nShould merging the Advisory Forum and the Scientific Panel prove infeasible, an\nalternative solution could be to better coordinate their operations, for example, through\nclear separations of scopes, roles, and tasks, but unified reporting. While not as ideal as a\ncomplete merger, this approach could streamline the reporting process by creating a\ncommon framew",
    "source": "naive",
    "offset": 104
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_105",
    "text": " through\nclear separations of scopes, roles, and tasks, but unified reporting. While not as ideal as a\ncomplete merger, this approach could streamline the reporting process by creating a\ncommon framework for both groups to communicate their findings and recommendations.\nThis might entail producing a joint annual report consolidating contributions from the\nForum and the Panel, thereby cutting administrative overlap and ensuring a more unified\nadvisory voice to the Commission, the Board, and the Member States.\nMerging or enhancing coordination between the Advisory Forum and Scientific\nPanel, complemented by creating subcommittees, favors robust governance of the AIA by\nstreamlining advisory roles for agility and innovation, also in response to disruptive\ntechnological changes.\n40 M Scholten and M van Rijsbergen, “The Limits of Agencification in the European Union” (2014) 15 German\nLaw Journal 1223; M Chamon, “Setting the Scene: EU Agencies, Agencification, and the EU Administration” in M",
    "source": "naive",
    "offset": 105
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_106",
    "text": "and M van Rijsbergen, “The Limits of Agencification in the European Union” (2014) 15 German\nLaw Journal 1223; M Chamon, “Setting the Scene: EU Agencies, Agencification, and the EU Administration” in M\nChamon (ed), EU Agencies: Legal and Political Limits to the Transformation of the EU Administration (Oxford University\nPress 2016) <https://doi.org/10.1093/acprof:oso/9780198784487.003.0002> accessed 29 January 2024; A Koene\nand others, “A Governance Framework for Algorithmic Accountability and Transparency” <https://nottingham-\nrepository.worktribe.com/index.php/output/3979928/a-governance-framework-for-algorithmic-accountability-\nand-transparency> (accessed 3 February 2022).\n22\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nVI.3. Coordinating overlapping EU entities: the case for an AI Coordination Hub\nAs AI technologies proliferate across the EU, collaboration among various regulatory\nentities becomes increasingly critical, esp",
    "source": "naive",
    "offset": 106
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_107",
    "text": "ordinating overlapping EU entities: the case for an AI Coordination Hub\nAs AI technologies proliferate across the EU, collaboration among various regulatory\nentities becomes increasingly critical, especially when introducing new AI applications\nintersects with conflicting interests. A case in point is the independent decision by Italy’s\ndata protection authority, ‘Garante per la privacy’, to suspend ChatGPT, a move not\nmirrored by other data protection entities within the EU.41 The scope for such overlaps is\nnot limited to national data protection authorities but extends to other entities, such as\ndecentralised agencies, including the European Data Protection Board (EDPB), the\nEuropean Union Agency for Cybersecurity (ENISA), the Fundamental Rights Agency (FRA),\nthe European Medicines Agency (EMA), the European Banking Authority (EBA), and the\nEuropean Union Intellectual Property Office (EUIPO). The likelihood of overlaps and\ninterferences with the constellation of bodies now introduced",
    "source": "naive",
    "offset": 107
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_108",
    "text": "y (EMA), the European Banking Authority (EBA), and the\nEuropean Union Intellectual Property Office (EUIPO). The likelihood of overlaps and\ninterferences with the constellation of bodies now introduced by the AIA – e.g., the Office,\nthe Board, the Forum, etc. – is high.\nIn light of these challenges, it becomes crucial to incorporate efficient coordination\nmechanisms within the EU’s legislative framework. Enhancing the functionality of the\nexisting EU Agency Network42, to foster a collaborative environment and act as a unified\npoint of communication for all EU agencies and Joint Undertakings (JUs) on multifaceted\nissues, would mark a significant advancement. However, establishing a centralised\nplatform, the European Union Artificial Intelligence Coordination Hub (EU AICH), emerges\nas a compelling alternative. This hub would convene all pertinent bodies involved in AI\nregulation and oversight, facilitating collective decision-making. Establishing such a hub\npromises to elevate significant",
    "source": "naive",
    "offset": 108
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_109",
    "text": "lling alternative. This hub would convene all pertinent bodies involved in AI\nregulation and oversight, facilitating collective decision-making. Establishing such a hub\npromises to elevate significantly the uniformity of AIA enforcement, improve operational\nefficiency, and reduce inconsistencies in treating similar matters.\nVI.4. Control of AI misuse at the EU level\nThe AI Board’s lack of authority to revise or address decisions made by national\nauthorities, in contrast to the European Data Protection Board’s role under GDPR, creates a\nsignificant gap in ensuring consistent AI regulation across the EU. This deficiency could\nresult in divergent interpretations and applications of the AIA, similar to the challenges\nobserved with the GDPR, particularly in cases such as the Irish Data Protection\nCommission’s oversight of major tech firms. Such inconsistencies are concerning,\nespecially regarding the AIA’s restrictions on surveillance tools, including facial\nrecognition technologies. Withou",
    "source": "naive",
    "offset": 109
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_110",
    "text": "on\nCommission’s oversight of major tech firms. Such inconsistencies are concerning,\nespecially regarding the AIA’s restrictions on surveillance tools, including facial\nrecognition technologies. Without the ability to correct or harmonise national decisions,\nthere’s a heightened risk that AI could be misused in some Member States, potentially\nfacilitating the establishment of illiberal surveillance regimes, and stifling legitimate\ndissent. This scenario underscores the need for a mechanism within the AI Board to ensure\nuniform law enforcement and prevent AI’s abusive applications, especially in sensitive\nareas like biometric surveillance.\nVI.5. Learning mechanisms\nGiven their capacity for more rapid development and adjustment, the agility of\nnon-legislative acts presents an opportunity for responsive governance in AI. However,\nthe agility of the regulatory framework must be matched by the regulatory bodies’\n41 Instead, following a request from Noyb, the European Center for Digital Right",
    "source": "naive",
    "offset": 110
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_111",
    "text": "responsive governance in AI. However,\nthe agility of the regulatory framework must be matched by the regulatory bodies’\n41 Instead, following a request from Noyb, the European Center for Digital Rights, the Austrian Data Protection\nAgency is set to examine GDPR compliance issues related to ChatGPT, focusing particularly on its tendency to\ngenerate inaccurate information. Noyb, “ChatGPT provides false information about people, and OpenAI can’t\ncorrect it”, Noyb blog (29 April 2024), https://noyb.eu/en/chatgpt-provides-false-information-about-people-and-\nopenai-cant-correct-it.\n42 https://agencies-network.europa.eu/index_en.\nEuropean Journal of Risk Regulation\n23\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nadaptability. Inter- and intra-agency learning and collaboration mechanisms are essential\nfor addressing AI’s multifaceted technical and social challenges.43 This approach should\nfacilitate continuous improvement and adaptation of regulatory pract",
    "source": "naive",
    "offset": 111
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_112",
    "text": "and collaboration mechanisms are essential\nfor addressing AI’s multifaceted technical and social challenges.43 This approach should\nfacilitate continuous improvement and adaptation of regulatory practices to ensure they\nremain effective in guiding and governing AI technologies’ legal and safe development and\ndeployment. To this end, specific ex-ante and ex-post review obligations of the Office’s and\nBoard’s actions and recommendations could be introduced. More importantly, a dedicated\nunit, for example, within the AI Office, should be tasked with identifying best and worst\npractices across all involved entities (from the Office to the Forum). Liaising with Member\nState competence centers, such a unit could become a hub for institutional and individual\nlearning and refinement of AI, within and beyond the AIA framework.\nVI.6. (Near) future challenges\nIn this paper, we have primarily focused on the structural design of the AIA’s institutional\nframework. However, in the near future, additi",
    "source": "naive",
    "offset": 112
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_113",
    "text": "and beyond the AIA framework.\nVI.6. (Near) future challenges\nIn this paper, we have primarily focused on the structural design of the AIA’s institutional\nframework. However, in the near future, additional challenges will likely arise concerning\nthe interplay between the AIA and other national and international AI regulations. At the\nEU level, effective enforcement of the AIA will require careful coordination, particularly in\nlight of potential overlaps with implementing other frameworks, such as the GDPR, DMA,\nand DSA, which are frequently overseen by specialised regulatory authorities.\nInternationally, the need for alignment is equally pressing. For instance, how will the\nAIA’s implementation bodies coordinate with those established under US or Chinese\nlegislation? China has enacted several targeted AI regulations, including those explicitly\naddressing Generative AI.44 By contrast, the United States currently lacks a formal AI\ngovernance model, as the existing legal framework (Biden’s",
    "source": "naive",
    "offset": 113
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_114",
    "text": "al targeted AI regulations, including those explicitly\naddressing Generative AI.44 By contrast, the United States currently lacks a formal AI\ngovernance model, as the existing legal framework (Biden’s Executive Order) has limited\nscope and enforcement mechanisms.45 However, it is expected that more stringent federal\n(e.g., on deep fakes) and state-level legislation (e.g., the California AI Bill) will follow, likely\nleading to the creation of new governance structures and implementation authorities.\nDiverging state-level rules may, in fact, result in a problematic patchwork even within the\nUS, making alignment with the AIA even trickier.\nGiven the United States’ dominance of the AI market, the actions of these US authorities\nwill inevitably influence the operations of their EU counterparts. Therefore, to foster\nconstructive collaboration and avoid uncritical emulation, different nation-states and\nsupranational bodies must establish shared objectives and encourage active participation\nin",
    "source": "naive",
    "offset": 114
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_115",
    "text": " Therefore, to foster\nconstructive collaboration and avoid uncritical emulation, different nation-states and\nsupranational bodies must establish shared objectives and encourage active participation\nin international forums regarding AI governance, such as the OECD AI Policy Observatory.\nSuch collaboration will help ensure a consistent and effective approach to AI regulation\nacross jurisdictions.\nAdditionally, the emergence of transnational and international legal documents on AI,\nsuch as the Council of Europe’s Framework Convention on Artificial Intelligence, raises\nfurther considerations. The Convention, drafted by the forty-six Member States of the\nCouncil of Europe, along with observer states like the United States, Canada and Japan will\nbe the first-ever international legally binding treaty in this field. It will be crucial to\nestablish a mechanism for interaction between the implementation structures of the AIA\nand those of the Convention, which includes a follow-up mechanism, the ",
    "source": "naive",
    "offset": 115
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_116",
    "text": "eaty in this field. It will be crucial to\nestablish a mechanism for interaction between the implementation structures of the AIA\nand those of the Convention, which includes a follow-up mechanism, the Conference of the\nParties. This body, composed of official representatives of the Convention’s Parties,\nperiodically monitors the implementation of the Convention’s provisions (Article 23 of the\n43 Dimitropoulos and Hacker (n 10).\n44 See, e.g., R Creemers, “The Regulation of Generative AI in China, forthcoming” in P Hacker, A Engel,\nS Hammer, and B Mittelstadt (eds), The Oxford Handbook of the Foundation and Regulation of Generative AI (Oxford\nUniversity Press forthcoming 2024).\n45 M Wörsdörfer, “Biden’s Executive Order on AI and the E.U.’s AI Act: A Comparative Computer-Ethical\nAnalysis” (2024) 37 Philosophy & Technology 74.\n24\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nConvention) and has the authority to resolve disputes bet",
    "source": "naive",
    "offset": 116
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_117",
    "text": "4) 37 Philosophy & Technology 74.\n24\nClaudio Novelli et al.\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\nConvention) and has the authority to resolve disputes between Parties regarding the\ninterpretation or application of the treaty (Article 29 of the Convention).\nVII. Conclusions\nAn intricate, yet solid foundation for AI governance has been introduced in the AIA.\nHowever, this article calls for a forward-looking perspective on AI governance, stressing\nthe importance of anticipatory regulation and the adaptive capabilities of governance\nstructures to keep pace with technological advancements. The article makes five key\nproposals. First, it suggests establishing the AI Office as a decentralised agency like EFSA or\nEMA to enhance its autonomy and reduce potential influences from political agendas at\nthe Commission level. Second, there is potential for consolidating the AI Office’s advisory\nbodies – the Advisory Forum and the Scientific Panel – into a",
    "source": "naive",
    "offset": 117
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_118",
    "text": "potential influences from political agendas at\nthe Commission level. Second, there is potential for consolidating the AI Office’s advisory\nbodies – the Advisory Forum and the Scientific Panel – into a single entity to streamline\ndecision-making and improve the quality of advice; this body would reflect both technical\nand societal implications of AI. Third, the article discusses the need for more coherent\ndecision-making and cooperation among the various EU bodies involved in AI oversight,\nwhich may have overlapped or conflicting jurisdictions. This need could be addressed by\nstrengthening the existing EU Agency Network or creating an EU AI Coordination Hub.\nFourth, the lack of authority for the AI Board to revise national decisions could lead to\ninconsistent application of AI regulations across Member States, like issues observed with\nGDPR enforcement. Fifth, to ensure responsive and effective governance of AI\ntechnologies, it proposes introducing mechanisms for continuous learning and",
    "source": "naive",
    "offset": 118
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_119",
    "text": "cross Member States, like issues observed with\nGDPR enforcement. Fifth, to ensure responsive and effective governance of AI\ntechnologies, it proposes introducing mechanisms for continuous learning and adaptation\nwithin the regulatory framework, including a dedicated unit within the AI Office to\nidentify and share best (and worst) practices. The article also calls for simplifying\nregulatory frameworks to aid compliance, especially for SMEs, and underscores the\nimportance of agile regulatory practices capable of adapting to the rapidly evolving AI\nlandscape, ensuring continuous improvement and effective governance.\nLooking ahead, the outlook for the governance of AI in the EU remains promising and\nchallenging. As AI technologies continue to evolve rapidly, the governance structures\nestablished by the AIA must remain flexible and adaptive, in short robust, to address new\ndevelopments and unforeseen risks. Ongoing research, stakeholder engagement, and\ninternational cooperation will be esse",
    "source": "naive",
    "offset": 119
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_120",
    "text": "ed by the AIA must remain flexible and adaptive, in short robust, to address new\ndevelopments and unforeseen risks. Ongoing research, stakeholder engagement, and\ninternational cooperation will be essential in refining and updating the regulatory\nframework. The future of AI governance will likely involve a dynamic balance between\nproviding legal certainty for AI developers and deployers while keeping some terms and\nconcepts strategically vague to cover forthcoming AI advancements. The multilevel\nstructure discussed, ranging from principles in the AIA to rules in delegated and\nimplementing acts, technical standards, and extensive guidance, may combine such safe\nharbors with open-textured terminology.\nCompeting interests. The author(s) declare none.\nCite this article: C Novelli, P Hacker, J Morley, J Trondal, and L Floridi, “A Robust Governance for the AI Act: AI\nOffice, AI Board, Scientific Panel, and National Authorities”. European Journal of Risk Regulation. https://doi.org/\n10.1017/er",
    "source": "naive",
    "offset": 120
  },
  {
    "id": "A_Robust_Governance_for_the_AI_Act_naive_121",
    "text": "orley, J Trondal, and L Floridi, “A Robust Governance for the AI Act: AI\nOffice, AI Board, Scientific Panel, and National Authorities”. European Journal of Risk Regulation. https://doi.org/\n10.1017/err.2024.57\nEuropean Journal of Risk Regulation\n25\nhttps://doi.org/10.1017/err.2024.57 Published online by Cambridge University Press\n",
    "source": "naive",
    "offset": 121
  }
]